{
  "meta": {
    "site": "https://github.com/zengfr/n8n-workflow-all-templates",
    "name": "Facebook Messenger Chatbot That Learns From Your Documents",
    "wechat": "youandme10086",
    "id": 12848,
    "update_time": "2026-02-13"
  },
  "name": "Facebook Messenger AI Chatbot with Pinecone RAG",
  "tags": [],
  "nodes": [
    {
      "id": "866ee81f-f01b-4f5f-a1b8-d4d005a262ea",
      "name": "Sticky Note - Overview",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        5008,
        3056
      ],
      "parameters": {
        "color": 4,
        "width": 520,
        "height": 800,
        "content": "# Facebook Messenger AI Chatbot with Pinecone RAG\n\n## Who is this for?\nBusinesses who want to automate customer interactions on Facebook Messenger using AI that can answer questions from your documents.\n\n## What does it do?\n- Receives messages from Facebook Messenger\n- Batches rapid consecutive messages together\n- Retrieves relevant context from your documents via Pinecone Assistant\n- Processes messages with OpenAI (GPT-4o-mini)\n- Maintains conversation memory\n- Sends intelligent AI responses with document citations\n\n## Setup Requirements\n1. **Facebook App** with Messenger product enabled\n2. **Facebook Page** connected to the app\n3. **OpenAI API Key**\n4. **Pinecone Account** with Assistant created\n5. **Pinecone Assistant community node** installed\n\n## Quick Start\n1. Install the Pinecone Assistant community node\n2. Configure credentials (Facebook, OpenAI, Pinecone)\n3. Create a Pinecone Assistant and upload your documents\n4. Set your verify token in \"Is Token Valid?\" node\n5. Update the Assistant name in \"Pinecone Assistant Tool\" node\n6. Publish the workflow\n7. Configure Facebook webhook URL\n8. Test by messaging your Facebook Page!\n\n"
      },
      "typeVersion": 1
    },
    {
      "id": "cda30df8-a761-4dfa-b655-2b8a07288261",
      "name": "Sticky Note - Webhook Verification",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        5600,
        2768
      ],
      "parameters": {
        "color": 7,
        "width": 520,
        "height": 280,
        "content": "## 1. Webhook Verification\n\nFacebook sends a GET request to verify your webhook URL during setup.\n\n**How it works:**\n1. Facebook sends `hub.verify_token` and `hub.challenge`\n2. We validate the token matches your secret\n3. If valid, return the challenge to confirm\n4. If invalid, return 403 Forbidden\n\n**Important:** Change `YOUR_VERIFY_TOKEN_HERE` in the \"Is Token Valid?\" node to your own secret token."
      },
      "typeVersion": 1
    },
    {
      "id": "12b7a811-0266-40f7-9b71-479d2407e9b2",
      "name": "Sticky Note - Message Receipt",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        5616,
        3728
      ],
      "parameters": {
        "color": 7,
        "width": 540,
        "height": 332,
        "content": "## 2. Receive & Filter Messages\n\nHandles incoming POST requests from Facebook when users send messages.\n\n**How it works:**\n1. Immediately acknowledge with `EVENT_RECEIVED` (required by Facebook)\n2. Filter out:\n   - Echo messages (messages we sent)\n   - Non-text messages\n   - Empty messages\n\nOnly valid user text messages proceed to processing."
      },
      "typeVersion": 1
    },
    {
      "id": "3164fd54-2389-4e8c-9bf1-b6e3d5d9949f",
      "name": "Sticky Note - Message Batching",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        6320,
        3040
      ],
      "parameters": {
        "color": 7,
        "width": 740,
        "height": 300,
        "content": "## 3. Message Batching (Smart Feature!)\n\nUsers often send multiple quick messages. This section combines them into one request.\n\n**How it works:**\n1. Store each message in workflow static data\n2. Send \"seen\" indicator so user knows we received it\n3. Wait 3 seconds for additional messages\n4. Combine all messages from the same user\n5. Process as a single conversation turn\n\n**Benefit:** Reduces API calls and provides more context to the AI."
      },
      "typeVersion": 1
    },
    {
      "id": "63db4412-d223-4a93-8f6d-be45941301c3",
      "name": "Sticky Note - AI Processing",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        7536,
        2784
      ],
      "parameters": {
        "color": 7,
        "width": 480,
        "height": 480,
        "content": "## 4. AI Agent with Pinecone RAG\n\nThe brain of the chatbot - powered by OpenAI + Pinecone.\n\n**Components:**\n- **OpenAI Chat Model:** Uses GPT-4o-mini for responses\n- **Conversation Memory:** Remembers last 50 messages per user\n- **Pinecone Assistant Tool:** Retrieves relevant context from your documents\n\n**RAG Features:**\n- Searches your documents for relevant information\n- Provides citations from source documents\n- Acknowledges when information is not available\n- Maintains context across conversations\n\n**Customize:**\n- Edit the system prompt in the AI Agent node\n- Change the Assistant name in Pinecone Assistant Tool\n- Upload documents to your Pinecone Assistant"
      },
      "typeVersion": 1
    },
    {
      "id": "a0f6ec23-6bc9-45ee-b1f0-944f06d6d5e1",
      "name": "Sticky Note - Pinecone Setup",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        7856,
        3712
      ],
      "parameters": {
        "color": 3,
        "width": 400,
        "height": 280,
        "content": "### Pinecone Setup\n\n1. Create account at [pinecone.io](https://www.pinecone.io)\n2. Create an Assistant named `n8n-assistant`\n3. Upload your documents to the Assistant\n4. Get your API key from the Pinecone console\n5. In n8n: Install the community node:\n   `@pinecone-database/n8n-nodes-pinecone-assistant`\n6. Create Pinecone credential with your API key\n7. Update the Assistant name in the tool node"
      },
      "typeVersion": 1
    },
    {
      "id": "1ae54fd5-b47a-4f87-b94c-4c5535ddac0e",
      "name": "Sticky Note - OpenAI Setup",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        7168,
        3760
      ],
      "parameters": {
        "color": 3,
        "width": 380,
        "height": 216,
        "content": "### OpenAI Credential Setup\n\n1. Go to [OpenAI API Keys](https://platform.openai.com/api-keys)\n2. Click **Create new secret key**\n3. Copy the key\n4. In n8n: Click the OpenAI node -> Credential -> Create New\n5. Paste your API key and save"
      },
      "typeVersion": 1
    },
    {
      "id": "a1965c3c-2d3b-4a67-b10f-197ebca239b8",
      "name": "Sticky Note - Response",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        8064,
        2976
      ],
      "parameters": {
        "color": 7,
        "width": 540,
        "height": 280,
        "content": "## 5. Format & Send Response\n\n**How it works:**\n1. Format AI response for Messenger (remove markdown)\n2. Truncate if over 1900 characters\n3. Send via Facebook Graph API\n\n**Response includes:**\n- Proper recipient ID\n- Message type: RESPONSE\n- Clean, readable text"
      },
      "typeVersion": 1
    },
    {
      "id": "67a7da1b-8110-48be-824c-d3429a8f8054",
      "name": "Sticky Note - Facebook Setup",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        6384,
        3632
      ],
      "parameters": {
        "color": 3,
        "width": 460,
        "height": 240,
        "content": "### Facebook Graph API Credential Setup\n\n1. Create a Facebook App at [developers.facebook.com](https://developers.facebook.com)\n2. Add **Messenger** product to your app\n3. Connect a Facebook Page\n4. Generate a **Page Access Token**\n5. In n8n: Create Facebook Graph API credential\n6. Paste the Page Access Token"
      },
      "typeVersion": 1
    },
    {
      "id": "5c1c1a54-5e97-429f-a944-8264882d9dc7",
      "name": "Facebook Verification Webhook",
      "type": "n8n-nodes-base.webhook",
      "position": [
        5632,
        3168
      ],
      "webhookId": "facebook-messenger-webhook-verify",
      "parameters": {
        "path": "facebook-messenger-webhook",
        "options": {},
        "responseMode": "responseNode"
      },
      "typeVersion": 2
    },
    {
      "id": "cd320e99-8f67-4499-827c-f440cc49bd40",
      "name": "Facebook Message Webhook",
      "type": "n8n-nodes-base.webhook",
      "position": [
        5648,
        3520
      ],
      "webhookId": "facebook-messenger-webhook-message",
      "parameters": {
        "path": "facebook-messenger-webhook",
        "options": {},
        "httpMethod": "POST",
        "responseMode": "responseNode"
      },
      "typeVersion": 2
    },
    {
      "id": "9ea3708e-d19c-4c40-819c-77fa7e709154",
      "name": "Is Token Valid?",
      "type": "n8n-nodes-base.if",
      "position": [
        5856,
        3168
      ],
      "parameters": {
        "options": {},
        "conditions": {
          "options": {
            "version": 1,
            "leftValue": "",
            "caseSensitive": true,
            "typeValidation": "strict"
          },
          "combinator": "and",
          "conditions": [
            {
              "id": "verify-token",
              "operator": {
                "type": "string",
                "operation": "equals"
              },
              "leftValue": "={{ $json.query['hub.verify_token'] }}",
              "rightValue": "YOUR_VERIFY_TOKEN_HERE"
            }
          ]
        }
      },
      "typeVersion": 2
    },
    {
      "id": "d21d92ed-91b8-44f9-bef2-6d9694d285f1",
      "name": "Respond with Challenge",
      "type": "n8n-nodes-base.respondToWebhook",
      "position": [
        6080,
        3088
      ],
      "parameters": {
        "options": {},
        "respondWith": "text",
        "responseBody": "={{ $json.query['hub.challenge'] }}"
      },
      "typeVersion": 1.1
    },
    {
      "id": "80e766d3-414c-4597-bf8e-9ae5ce9c47a8",
      "name": "Respond Forbidden",
      "type": "n8n-nodes-base.respondToWebhook",
      "position": [
        6080,
        3248
      ],
      "parameters": {
        "options": {
          "responseCode": 403
        },
        "respondWith": "text",
        "responseBody": "Verification failed"
      },
      "typeVersion": 1.1
    },
    {
      "id": "20969b8e-8f11-4881-a0a9-4df73532bc52",
      "name": "Acknowledge Event",
      "type": "n8n-nodes-base.respondToWebhook",
      "position": [
        5872,
        3520
      ],
      "parameters": {
        "options": {
          "responseCode": 200
        },
        "respondWith": "text",
        "responseBody": "EVENT_RECEIVED"
      },
      "typeVersion": 1.1
    },
    {
      "id": "dbd43cd0-f776-49e8-9071-d191a6c48389",
      "name": "Filter Valid Messages",
      "type": "n8n-nodes-base.if",
      "position": [
        6096,
        3520
      ],
      "parameters": {
        "options": {},
        "conditions": {
          "options": {
            "leftValue": "",
            "caseSensitive": true,
            "typeValidation": "loose"
          },
          "combinator": "and",
          "conditions": [
            {
              "id": "has-message",
              "operator": {
                "type": "string",
                "operation": "exists"
              },
              "leftValue": "={{ $json.body?.entry?.[0]?.messaging?.[0]?.message?.text }}",
              "rightValue": ""
            },
            {
              "id": "not-echo",
              "operator": {
                "type": "boolean",
                "operation": "notEquals"
              },
              "leftValue": "={{ $json.body?.entry?.[0]?.messaging?.[0]?.message?.is_echo }}",
              "rightValue": true
            }
          ]
        }
      },
      "typeVersion": 2
    },
    {
      "id": "d16aa51b-896a-4660-9da3-a8a9c5dcc4cc",
      "name": "Store Message for Batching",
      "type": "n8n-nodes-base.code",
      "position": [
        6320,
        3424
      ],
      "parameters": {
        "jsCode": "// Extract message data from Facebook webhook\nconst entry = $input.first().json.body?.entry?.[0];\nconst messaging = entry?.messaging?.[0];\n\nconst userId = messaging?.sender?.id;\nconst pageId = messaging?.recipient?.id;\nconst messageText = messaging?.message?.text;\nconst timestamp = messaging?.timestamp || Date.now();\nconst messageId = messaging?.message?.mid;\n\n// Store in workflow static data for batching\nconst staticData = $getWorkflowStaticData('global');\n\nif (!staticData.messageBatches) {\n  staticData.messageBatches = {};\n}\n\nif (!staticData.messageBatches[userId]) {\n  staticData.messageBatches[userId] = {\n    messages: [],\n    firstMessageTime: timestamp,\n    pageId: pageId\n  };\n}\n\nstaticData.messageBatches[userId].messages.push({\n  text: messageText,\n  timestamp: timestamp,\n  messageId: messageId\n});\n\nreturn {\n  json: {\n    userId,\n    pageId,\n    messageText,\n    timestamp,\n    messageId,\n    batchCount: staticData.messageBatches[userId].messages.length\n  }\n};"
      },
      "typeVersion": 2
    },
    {
      "id": "afd69549-cb23-4fa6-9312-df2694e3fa2e",
      "name": "Send Seen Indicator",
      "type": "n8n-nodes-base.httpRequest",
      "onError": "continueRegularOutput",
      "position": [
        6544,
        3424
      ],
      "parameters": {
        "url": "=https://graph.facebook.com/v21.0/me/messages",
        "method": "POST",
        "options": {},
        "jsonBody": "={\n  \"recipient\": {\n    \"id\": \"{{ $json.userId }}\"\n  },\n  \"sender_action\": \"mark_seen\"\n}",
        "sendBody": true,
        "specifyBody": "json",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "facebookGraphApi"
      },
      "credentials": {
        "facebookGraphApi": {
          "id": "REPLACE_WITH_YOUR_CREDENTIAL_ID",
          "name": "Facebook Graph API"
        }
      },
      "typeVersion": 4.2,
      "alwaysOutputData": true
    },
    {
      "id": "71c1f6fc-aeb8-43e2-95a3-fc6e2971e518",
      "name": "Wait 3 Seconds",
      "type": "n8n-nodes-base.wait",
      "position": [
        6768,
        3424
      ],
      "webhookId": "wait-batch",
      "parameters": {
        "amount": 3
      },
      "typeVersion": 1.1
    },
    {
      "id": "12f6e864-7a6f-471a-b321-70eb5fbdfcc3",
      "name": "Retrieve Batched Messages",
      "type": "n8n-nodes-base.code",
      "position": [
        6992,
        3424
      ],
      "parameters": {
        "jsCode": "// Retrieve all batched messages for this user\n// Get userId from Store node directly (not from input, which is HTTP response)\nconst userId = $('Store Message for Batching').first().json.userId;\nconst pageId = $('Store Message for Batching').first().json.pageId;\n\nconst staticData = $getWorkflowStaticData('global');\nconst userBatch = staticData.messageBatches?.[userId];\n\nif (!userBatch || userBatch.messages.length === 0) {\n  return { json: { skip: true } };\n}\n\n// Combine all messages into one\nconst combinedMessage = userBatch.messages\n  .sort((a, b) => a.timestamp - b.timestamp)\n  .map(m => m.text)\n  .join(' ');\n\n// Clear the batch\ndelete staticData.messageBatches[userId];\n\nreturn {\n  json: {\n    userId,\n    pageId,\n    combinedMessage,\n    messageCount: userBatch.messages.length,\n    skip: false\n  }\n};"
      },
      "typeVersion": 2
    },
    {
      "id": "9475f390-beed-4654-9883-ac2940b79233",
      "name": "Has Messages to Process?",
      "type": "n8n-nodes-base.if",
      "position": [
        7216,
        3424
      ],
      "parameters": {
        "options": {},
        "conditions": {
          "options": {
            "version": 1,
            "leftValue": "",
            "caseSensitive": true,
            "typeValidation": "strict"
          },
          "combinator": "and",
          "conditions": [
            {
              "id": "not-skip",
              "operator": {
                "type": "boolean",
                "operation": "equals"
              },
              "leftValue": "={{ $json.skip }}",
              "rightValue": false
            }
          ]
        }
      },
      "typeVersion": 2
    },
    {
      "id": "54254117-c8b2-4ff6-becd-7ae6c8b4db8d",
      "name": "Send Typing Indicator",
      "type": "n8n-nodes-base.httpRequest",
      "onError": "continueRegularOutput",
      "position": [
        7440,
        3328
      ],
      "parameters": {
        "url": "=https://graph.facebook.com/v21.0/me/messages",
        "method": "POST",
        "options": {},
        "jsonBody": "={\n  \"recipient\": {\n    \"id\": \"{{ $json.userId }}\"\n  },\n  \"sender_action\": \"typing_on\"\n}",
        "sendBody": true,
        "specifyBody": "json",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "facebookGraphApi"
      },
      "credentials": {
        "facebookGraphApi": {
          "id": "REPLACE_WITH_YOUR_CREDENTIAL_ID",
          "name": "Facebook Graph API"
        }
      },
      "typeVersion": 4.2,
      "alwaysOutputData": true
    },
    {
      "id": "0e8e3e5f-c153-4dd0-913b-94cfba179f66",
      "name": "Conversation Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "position": [
        7632,
        3632
      ],
      "parameters": {
        "sessionKey": "={{ $('Retrieve Batched Messages').first().json.userId }}",
        "sessionIdType": "customKey",
        "contextWindowLength": 50
      },
      "typeVersion": 1.3
    },
    {
      "id": "7f12fd6e-392c-48bd-b247-31e4e7582ba0",
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        7296,
        3632
      ],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4o-mini",
          "cachedResultName": "gpt-4o-mini"
        },
        "options": {}
      },
      "credentials": {
        "openAiApi": {
          "id": "REPLACE_WITH_YOUR_CREDENTIAL_ID",
          "name": "OpenAI API"
        }
      },
      "typeVersion": 1.2
    },
    {
      "id": "3ada67ba-1bf5-4e72-8947-09a0b15e55c6",
      "name": "Format Response",
      "type": "n8n-nodes-base.code",
      "position": [
        8064,
        3328
      ],
      "parameters": {
        "jsCode": "// Format AI response for Facebook Messenger\nconst aiResponse = $input.first().json.output || $input.first().json.text || '';\nconst userId = $('Retrieve Batched Messages').first().json.userId;\nconst pageId = $('Retrieve Batched Messages').first().json.pageId;\n\n// Messenger has a 2000 character limit per message\nlet formattedResponse = aiResponse.trim();\n\n// If response is too long, truncate it\nif (formattedResponse.length > 1900) {\n  formattedResponse = formattedResponse.substring(0, 1897) + '...';\n}\n\n// Remove any markdown formatting that doesn't render well in Messenger\nformattedResponse = formattedResponse\n  .replace(/\\*\\*(.+?)\\*\\*/g, '$1')  // Remove bold\n  .replace(/\\*(.+?)\\*/g, '$1')      // Remove italic\n  .replace(/```[\\s\\S]*?```/g, (match) => match.replace(/```\\w*\\n?/g, ''))  // Remove code blocks\n  .replace(/`(.+?)`/g, '$1');       // Remove inline code\n\nreturn {\n  json: {\n    userId,\n    pageId,\n    response: formattedResponse\n  }\n};"
      },
      "typeVersion": 2
    },
    {
      "id": "2cdd999c-7068-4d74-8a7b-7842ce6fc6e7",
      "name": "Send Response to User",
      "type": "n8n-nodes-base.httpRequest",
      "onError": "continueRegularOutput",
      "position": [
        8288,
        3328
      ],
      "parameters": {
        "url": "=https://graph.facebook.com/v21.0/me/messages",
        "method": "POST",
        "options": {},
        "jsonBody": "={\n  \"recipient\": {\n    \"id\": \"{{ $json.userId }}\"\n  },\n  \"messaging_type\": \"RESPONSE\",\n  \"message\": {\n    \"text\": {{ JSON.stringify($json.response) }}\n  }\n}",
        "sendBody": true,
        "specifyBody": "json",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "facebookGraphApi"
      },
      "credentials": {
        "facebookGraphApi": {
          "id": "REPLACE_WITH_YOUR_CREDENTIAL_ID",
          "name": "Facebook Graph API"
        }
      },
      "typeVersion": 4.2,
      "alwaysOutputData": true
    },
    {
      "id": "a53563d7-2886-456e-880e-8c3474f09a8b",
      "name": "Success",
      "type": "n8n-nodes-base.set",
      "position": [
        8512,
        3328
      ],
      "parameters": {
        "options": {}
      },
      "typeVersion": 3.4
    },
    {
      "id": "7e31988e-4371-4770-a4dc-37a2d95a1361",
      "name": "Get context snippets in Pinecone Assistant",
      "type": "@pinecone-database/n8n-nodes-pinecone-assistant.pineconeAssistantTool",
      "position": [
        8000,
        3552
      ],
      "parameters": {
        "assistantData": "{\"name\":\"YOUR_ASSISTANT_NAME\",\"host\":\"YOUR_PINECONE_HOST\"}",
        "additionalFields": {
          "sourceTag": "n8n:n8n_nodes_pinecone_assistant:quickstart"
        }
      },
      "credentials": {
        "pineconeAssistantApi": {
          "id": "REPLACE_WITH_YOUR_CREDENTIAL_ID",
          "name": "Pinecone Assistant API"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "187d190c-512f-41b6-a7fe-05863d5e3e04",
      "name": "AI Agent1",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        7712,
        3328
      ],
      "parameters": {
        "text": "={{ $('Retrieve Batched Messages').first().json.combinedMessage }}",
        "options": {
          "systemMessage": "You are a helpful assistant. Use the \"Get context snippets in Pinecone Assistant\" tool to retrieve relevant information from your knowledge base.\n\nYour Behavior:\n\n1. Use Your Knowledge Base: When users ask questions, ALWAYS use the \"Get context snippets in Pinecone Assistant\" tool to search for relevant information from your documents first.\n\n2. Cite Your Sources: When you find relevant information from documents, mention where it came from (e.g., \"According to our documentation...\" or \"Based on our records...\").\n\n3. Acknowledge Limitations: If the Pinecone search returns no relevant results or the information is not in your documents, clearly tell the user:\n   - \"I don't have specific information about that in my knowledge base.\"\n   - \"That topic isn't covered in my available documents.\"\n   - Do NOT make up answers or use general knowledge for questions that should be answered from documents.\n\n4. Conversation Style:\n   - Be concise and conversational - suitable for chat format\n   - Keep responses under 2000 characters (Messenger limit)\n   - Be friendly but professional\n   - End conversations gracefully when appropriate\n\n5. For General Chat: For greetings, small talk, or questions clearly not related to your documents, respond naturally without using the tool.\n\nRemember: You're chatting via Messenger, so keep responses appropriate for that medium."
        },
        "promptType": "define"
      },
      "typeVersion": 3
    }
  ],
  "active": false,
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "connections": {
    "AI Agent1": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait 3 Seconds": {
      "main": [
        [
          {
            "node": "Retrieve Batched Messages",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Response": {
      "main": [
        [
          {
            "node": "Send Response to User",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is Token Valid?": {
      "main": [
        [
          {
            "node": "Respond with Challenge",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Respond Forbidden",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Acknowledge Event": {
      "main": [
        [
          {
            "node": "Filter Valid Messages",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Conversation Memory": {
      "ai_memory": [
        [
          {
            "node": "AI Agent1",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Send Seen Indicator": {
      "main": [
        [
          {
            "node": "Wait 3 Seconds",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter Valid Messages": {
      "main": [
        [
          {
            "node": "Store Message for Batching",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Send Response to User": {
      "main": [
        [
          {
            "node": "Success",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Send Typing Indicator": {
      "main": [
        [
          {
            "node": "AI Agent1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Facebook Message Webhook": {
      "main": [
        [
          {
            "node": "Acknowledge Event",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has Messages to Process?": {
      "main": [
        [
          {
            "node": "Send Typing Indicator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Retrieve Batched Messages": {
      "main": [
        [
          {
            "node": "Has Messages to Process?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Store Message for Batching": {
      "main": [
        [
          {
            "node": "Send Seen Indicator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Facebook Verification Webhook": {
      "main": [
        [
          {
            "node": "Is Token Valid?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get context snippets in Pinecone Assistant": {
      "ai_tool": [
        [
          {
            "node": "AI Agent1",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    }
  }
}