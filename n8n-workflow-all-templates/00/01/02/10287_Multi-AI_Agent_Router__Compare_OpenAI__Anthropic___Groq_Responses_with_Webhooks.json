{
  "id": "8inUrLV1lxLoNc7e",
  "meta": {
    "site": "https://github.com/zengfr/n8n-workflow-all-templates",
    "name": "Multi-AI Agent Router: Compare OpenAI, Anthropic & Groq Responses with Webhooks",
    "wechat": "youandme10086",
    "id": 10287,
    "update_time": "2025-11-10"
  },
  "name": "Multi-AI Agent Router: Compare OpenAI, Anthropic & Groq Responses with Webhooks",
  "tags": [],
  "nodes": [
    {
      "id": "21041871-2233-477d-b2d3-2c63919050b5",
      "name": "Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "position": [
        -1008,
        -656
      ],
      "parameters": {},
      "typeVersion": 1.2
    },
    {
      "id": "80b943cb-94b6-45fa-8f97-a3fd2adb4c1c",
      "name": "Output Parser2",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "position": [
        -992,
        -368
      ],
      "parameters": {},
      "typeVersion": 1.2
    },
    {
      "id": "b4ae807f-c736-4987-9cf9-32a75d90b3b1",
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "position": [
        -1808,
        -800
      ],
      "webhookId": "d842ef53-fd5a-41e7-8371-12d5d6dbac30",
      "parameters": {
        "path": "ai-pipeline",
        "options": {},
        "httpMethod": "POST",
        "responseMode": "responseNode"
      },
      "typeVersion": 2
    },
    {
      "id": "4236a8f9-1acf-4031-a82b-502dd80831cd",
      "name": "Extract Input Parameters",
      "type": "n8n-nodes-base.set",
      "position": [
        -1648,
        -800
      ],
      "parameters": {
        "options": {},
        "assignments": {
          "assignments": [
            {
              "id": "input_data",
              "name": "input_data",
              "type": "string",
              "value": "={{ $json.body.data }}"
            },
            {
              "id": "task_type",
              "name": "task_type",
              "type": "string",
              "value": "={{ $json.body.task_type || 'general' }}"
            },
            {
              "id": "priority",
              "name": "priority",
              "type": "string",
              "value": "={{ $json.body.priority || 'balanced' }}"
            }
          ]
        }
      },
      "typeVersion": 3.4
    },
    {
      "id": "5b6eeb1c-415c-462b-8d71-5c3b20989ed3",
      "name": "Dynamic LLM Router",
      "type": "n8n-nodes-base.code",
      "position": [
        -1456,
        -800
      ],
      "parameters": {
        "jsCode": "// Dynamic LLM routing logic based on cost/performance\nconst inputData = $input.item.json.input_data;\nconst taskType = $input.item.json.task_type;\nconst priority = $input.item.json.priority;\n\n// Calculate complexity score\nconst dataLength = inputData.length;\nlet complexityScore = 0;\n\nif (dataLength < 500) complexityScore = 1;\nelse if (dataLength < 2000) complexityScore = 2;\nelse complexityScore = 3;\n\n// Routing decision matrix\nlet selectedProvider = '';\nlet modelName = '';\nlet estimatedCost = 0;\nlet expectedQuality = 0;\n\nif (priority === 'cost') {\n  // Prioritize low-cost providers\n  if (complexityScore === 1) {\n    selectedProvider = 'groq';\n    modelName = 'llama-3.1-8b-instant';\n    estimatedCost = 0.0001;\n    expectedQuality = 7;\n  } else if (complexityScore === 2) {\n    selectedProvider = 'ollama';\n    modelName = 'llama3';\n    estimatedCost = 0;\n    expectedQuality = 6;\n  } else {\n    selectedProvider = 'groq';\n    modelName = 'llama-3.1-70b-versatile';\n    estimatedCost = 0.0005;\n    expectedQuality = 8;\n  }\n} else if (priority === 'performance') {\n  // Prioritize high-quality providers\n  if (complexityScore === 1) {\n    selectedProvider = 'openai';\n    modelName = 'gpt-4o-mini';\n    estimatedCost = 0.002;\n    expectedQuality = 9;\n  } else if (complexityScore === 2) {\n    selectedProvider = 'anthropic';\n    modelName = 'claude-3-5-sonnet-20241022';\n    estimatedCost = 0.015;\n    expectedQuality = 10;\n  } else {\n    selectedProvider = 'openai';\n    modelName = 'gpt-4o';\n    estimatedCost = 0.025;\n    expectedQuality = 10;\n  }\n} else {\n  // Balanced approach\n  if (complexityScore === 1) {\n    selectedProvider = 'groq';\n    modelName = 'llama-3.1-8b-instant';\n    estimatedCost = 0.0001;\n    expectedQuality = 7;\n  } else if (complexityScore === 2) {\n    selectedProvider = 'openai';\n    modelName = 'gpt-4o-mini';\n    estimatedCost = 0.002;\n    expectedQuality = 9;\n  } else {\n    selectedProvider = 'anthropic';\n    modelName = 'claude-3-5-sonnet-20241022';\n    estimatedCost = 0.015;\n    expectedQuality = 10;\n  }\n}\n\nreturn {\n  input_data: inputData,\n  task_type: taskType,\n  priority: priority,\n  routing_decision: {\n    provider: selectedProvider,\n    model: modelName,\n    complexity_score: complexityScore,\n    estimated_cost: estimatedCost,\n    expected_quality: expectedQuality\n  },\n  timestamp: new Date().toISOString()\n};"
      },
      "typeVersion": 2
    },
    {
      "id": "c1042d78-0f4b-4dab-97f1-c080df3ab8bc",
      "name": "Route to Provider",
      "type": "n8n-nodes-base.switch",
      "position": [
        -1328,
        -688
      ],
      "parameters": {
        "rules": {
          "values": [
            {
              "outputKey": "openai",
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "1584bb13-fed5-457e-a871-99a0d3a81fbf",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $json.routing_decision.provider }}",
                    "rightValue": "openai"
                  }
                ]
              },
              "renameOutput": true
            },
            {
              "outputKey": "anthropic",
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "10edb531-ce74-4bf2-b795-a80fb0f80049",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $json.routing_decision.provider }}",
                    "rightValue": "anthropic"
                  }
                ]
              },
              "renameOutput": true
            },
            {
              "outputKey": "groq",
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "961d531e-d1e4-46ba-bd76-44a4999b0653",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $json.routing_decision.provider }}",
                    "rightValue": "groq"
                  }
                ]
              },
              "renameOutput": true
            }
          ]
        },
        "options": {}
      },
      "typeVersion": 3.2
    },
    {
      "id": "6c88c121-40c7-4313-8697-300dde7e5664",
      "name": "OpenAI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        -1152,
        -1056
      ],
      "parameters": {
        "text": "={{ \"You are a data enrichment AI assistant. Analyze and enrich the following data with insights, structure it properly, and provide actionable recommendations.\\n\\nTask Type: \" + $json.task_type + \"\\n\\nInput Data:\\n\" + $json.input_data + \"\\n\\nProvide:\\n1. Structured analysis\\n2. Key insights\\n3. Data enrichment\\n4. Actionable recommendations\\n5. Quality score (1-10)\\n\\nFormat as JSON.\" }}",
        "options": {
          "systemMessage": "=You are processing data with {{ $json.routing_decision.provider }} ({{ $json.routing_decision.model }}). Quality level: {{ $json.routing_decision.expected_quality }}/10."
        },
        "promptType": "define",
        "hasOutputParser": true
      },
      "typeVersion": 1.7
    },
    {
      "id": "278920ea-7712-4f58-9274-1b9869daa368",
      "name": "Anthropic Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        -1152,
        -800
      ],
      "parameters": {
        "text": "={{ \"You are a data enrichment AI assistant. Analyze and enrich the following data with insights, structure it properly, and provide actionable recommendations.\\n\\nTask Type: \" + $json.task_type + \"\\n\\nInput Data:\\n\" + $json.input_data + \"\\n\\nProvide:\\n1. Structured analysis\\n2. Key insights\\n3. Data enrichment\\n4. Actionable recommendations\\n5. Quality score (1-10)\\n\\nFormat as JSON.\" }}",
        "options": {
          "systemMessage": "=You are processing data with {{ $json.routing_decision.provider }} ({{ $json.routing_decision.model }}). Quality level: {{ $json.routing_decision.expected_quality }}/10."
        },
        "promptType": "define",
        "hasOutputParser": true
      },
      "typeVersion": 1.7
    },
    {
      "id": "09f9bc3c-184b-4865-ace9-b84518a15437",
      "name": "Groq Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        -1136,
        -528
      ],
      "parameters": {
        "text": "={{ \"You are a data enrichment AI assistant. Analyze and enrich the following data with insights, structure it properly, and provide actionable recommendations.\\n\\nTask Type: \" + $json.task_type + \"\\n\\nInput Data:\\n\" + $json.input_data + \"\\n\\nProvide:\\n1. Structured analysis\\n2. Key insights\\n3. Data enrichment\\n4. Actionable recommendations\\n5. Quality score (1-10)\\n\\nFormat as JSON.\" }}",
        "options": {
          "systemMessage": "=You are processing data with {{ $json.routing_decision.provider }} ({{ $json.routing_decision.model }}). Quality level: {{ $json.routing_decision.expected_quality }}/10."
        },
        "promptType": "define",
        "hasOutputParser": true
      },
      "typeVersion": 1.7
    },
    {
      "id": "5efa962a-2f6b-4834-8c0d-02452ff92233",
      "name": "Merge Results",
      "type": "n8n-nodes-base.merge",
      "position": [
        -784,
        -784
      ],
      "parameters": {
        "mode": "combine",
        "options": {}
      },
      "typeVersion": 3
    },
    {
      "id": "340f1fbc-31e7-44af-9649-52ea7de91418",
      "name": "Calculate Performance Metrics",
      "type": "n8n-nodes-base.code",
      "position": [
        -624,
        -784
      ],
      "parameters": {
        "jsCode": "// Calculate actual performance metrics\nconst startTime = new Date($input.first().json.timestamp).getTime();\nconst endTime = Date.now();\nconst processingTime = endTime - startTime;\n\nconst routingDecision = $input.first().json.routing_decision;\nconst aiResponse = $input.all()[1].json;\n\n// Extract quality score from AI response\nlet actualQuality = 0;\ntry {\n  actualQuality = aiResponse.quality_score || routingDecision.expected_quality;\n} catch (e) {\n  actualQuality = routingDecision.expected_quality;\n}\n\n// Performance evaluation\nconst costEfficiency = (actualQuality / routingDecision.estimated_cost).toFixed(2);\nconst performanceScore = ((actualQuality / 10) * 0.7 + (1 / (processingTime / 1000)) * 0.3).toFixed(2);\n\nreturn {\n  original_input: $input.first().json.input_data,\n  task_type: $input.first().json.task_type,\n  priority: $input.first().json.priority,\n  routing_decision: routingDecision,\n  enriched_data: aiResponse,\n  performance_metrics: {\n    processing_time_ms: processingTime,\n    actual_quality_score: actualQuality,\n    expected_quality_score: routingDecision.expected_quality,\n    estimated_cost: routingDecision.estimated_cost,\n    cost_efficiency: parseFloat(costEfficiency),\n    performance_score: parseFloat(performanceScore),\n    provider_used: routingDecision.provider,\n    model_used: routingDecision.model\n  },\n  timestamp: new Date().toISOString()\n};"
      },
      "typeVersion": 2
    },
    {
      "id": "9e130394-0a3c-42de-a702-1b010e15ff8c",
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "position": [
        -448,
        -784
      ],
      "parameters": {
        "options": {
          "responseCode": 200,
          "responseHeaders": {
            "entries": [
              {
                "name": "Content-Type",
                "value": "application/json"
              }
            ]
          }
        },
        "respondWith": "allIncomingItems"
      },
      "typeVersion": 1.1
    },
    {
      "id": "092da29d-efe6-4408-be28-c4360e94c8d3",
      "name": "OpenAI Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        -1168,
        -912
      ],
      "parameters": {
        "options": {}
      },
      "credentials": {
        "openAiApi": {
          "id": "OGYj7DgYv5GFLFZk",
          "name": "OpenAi account 2"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "9b471188-3126-4bd3-a61f-d0498f00ea3c",
      "name": "Output Parser1",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "position": [
        -1008,
        -912
      ],
      "parameters": {},
      "typeVersion": 1.2
    },
    {
      "id": "58b782f0-871d-450a-92a5-a8e27163a652",
      "name": "Groq Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "position": [
        -1136,
        -368
      ],
      "parameters": {
        "model": "llama-3.1-70b-versatile",
        "options": {}
      },
      "typeVersion": 1
    },
    {
      "id": "202e4932-082a-4dd2-b3de-c6859d622055",
      "name": "Anthropic Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "position": [
        -1152,
        -656
      ],
      "parameters": {
        "model": "claude-3-5-sonnet-20241022",
        "options": {}
      },
      "credentials": {
        "anthropicApi": {
          "id": "S8laStQPC1u3EYuZ",
          "name": "Anthropic account"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "16f3a535-b740-418c-8090-b5b9fcdde583",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -2352,
        -1104
      ],
      "parameters": {
        "width": 512,
        "height": 576,
        "content": "## Introduction\nThis workflow connects to OpenAI, Anthropic, and Groq, processing requests in parallel with automatic performance \nmetrics. Ideal for testing speed, cost, and quality across models.\n## How It Works\nWebhooks trigger parameter extraction and routing. Three AI agents run simultaneously with memory and\n parsing. Responses merge with detailed metrics.\n## Workflow Template\nWebhook → Extract Parameters → Router\n├→ OpenAI Agent\n├→ Anthropic Agent\n├→ Groq Agent\n→ Merge → Metrics → Respond\n## Workflow Steps\n1. Webhook receives POST with prompt and settings.\n2. Parameters extracted and validated.\n3. Router directs by cost, latency, or type.\n4. AI agents run in parallel.\n5. Results merged with metadata.\n6. Metrics compute time, cost, and quality.\n7. Response returns outputs and recommendation.\n"
      },
      "typeVersion": 1
    },
    {
      "id": "6bebceb0-7370-469d-8c94-9d54d0d33ceb",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -1808,
        -640
      ],
      "parameters": {
        "color": 5,
        "width": 400,
        "height": 464,
        "content": "## Setup Instructions\n1. Activate Webhook with authentication.\n2. Add API keys for all providers.\n3. Define models, tokens, and temperature.\n4. Adjust Router logic for selection.\n5. Tune Metrics scoring formulas.\n## Prerequisites\n* n8n v1.0+ instance\n* API keys: OpenAI, Anthropic, Groq\n* HTTP client for testing\n## Customization\nAdd providers like Gemini or Azure OpenAI.\nEnable routing by cost or performance.\n## Benefits\nAuto-select efficient providers and compare model performance in real time."
      },
      "typeVersion": 1
    }
  ],
  "active": false,
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "61425eed-0f21-4b21-a355-ef9669810241",
  "connections": {
    "Webhook": {
      "main": [
        [
          {
            "node": "Extract Input Parameters",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Groq Agent": {
      "main": [
        [
          {
            "node": "Merge Results",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Groq Model": {
      "ai_languageModel": [
        [
          {
            "node": "Groq Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Agent": {
      "main": [
        [
          {
            "node": "Merge Results",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "OpenAI Model": {
      "ai_languageModel": [
        [
          {
            "node": "OpenAI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Merge Results": {
      "main": [
        [
          {
            "node": "Calculate Performance Metrics",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Anthropic Agent",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Output Parser1": {
      "ai_outputParser": [
        [
          {
            "node": "OpenAI Agent",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Output Parser2": {
      "ai_outputParser": [
        [
          {
            "node": "Groq Agent",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Agent": {
      "main": [
        [
          {
            "node": "Merge Results",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Anthropic Model": {
      "ai_languageModel": [
        [
          {
            "node": "Anthropic Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Route to Provider": {
      "main": [
        [
          {
            "node": "OpenAI Agent",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Anthropic Agent",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Groq Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Dynamic LLM Router": {
      "main": [
        [
          {
            "node": "Route to Provider",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Input Parameters": {
      "main": [
        [
          {
            "node": "Dynamic LLM Router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Calculate Performance Metrics": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  }
}