{
  "nodes": [
    {
      "id": "60c2f847-f213-4ca2-8b93-85435a34613c",
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "position": [
        -176,
        496
      ],
      "webhookId": "eef2977c-81d7-4102-8edf-d771d9da2118",
      "parameters": {
        "options": {
          "responseMode": "responseNodes"
        }
      },
      "typeVersion": 1.3
    },
    {
      "id": "b99d2ceb-4a45-48b9-85ff-50d8b9e4c6fa",
      "name": "Very small model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        480,
        944
      ],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-nano",
          "cachedResultName": "gpt-4.1-nano"
        },
        "options": {}
      },
      "credentials": {
        "openAiApi": {
          "id": "dMiSy27YCK6c6rra",
          "name": "Duv's OpenAI"
        }
      },
      "typeVersion": 1.2
    },
    {
      "id": "798c5cdd-38b7-4883-979b-caf044011598",
      "name": "Simple response",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "position": [
        960,
        304
      ],
      "parameters": {
        "text": "={{ $('When chat message received').item.json.chatInput }}",
        "batching": {},
        "messages": {
          "messageValues": [
            {
              "message": "=You are a helpful assistant that assists the user.\n\nNB: Here are the previous messages from the conversation:\n\n{{ $('Find past messages').item.json.messages.toJsonString() }}"
            }
          ]
        },
        "promptType": "define"
      },
      "typeVersion": 1.7
    },
    {
      "id": "bd15aa9e-f288-4033-ba56-ae740f41de1f",
      "name": "Prepare retrieval query",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "position": [
        784,
        704
      ],
      "parameters": {
        "text": "={{ $('When chat message received').item.json.chatInput }}",
        "batching": {},
        "messages": {
          "messageValues": [
            {
              "message": "=Based on the user message, you will formulate the short and concise query to send through a knowledge retrieval tool that will enable you to retrieve all the information needed to actually answer that user message later on.\nDirectly output the query as a question.\n\nNB: Here are the previous messages from the conversation:\n\n{{ $('Find past messages').item.json.messages.toJsonString() }}"
            }
          ]
        },
        "promptType": "define"
      },
      "typeVersion": 1.7
    },
    {
      "id": "c07a6c01-9c13-47aa-896d-60e3f0f9992d",
      "name": "Write the final response",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "position": [
        1520,
        704
      ],
      "parameters": {
        "text": "=Initial query:\n\n\"{{ $('When chat message received').item.json.chatInput }}\"\n\nKnowledge retrieval output:\n\"{{ $json.Output }}\"",
        "batching": {},
        "messages": {
          "messageValues": [
            {
              "message": "=The user message contains a query and insights from a knowledge retrieval step to prepare you to actually write the final answer to that user.\n\nNB: Here are the previous messages from the conversation:\n\n{{ $('Find past messages').item.json.messages.toJsonString() }}"
            }
          ]
        },
        "promptType": "define"
      },
      "typeVersion": 1.7
    },
    {
      "id": "aa532ba1-b606-45c0-8bb2-baeb63daf714",
      "name": "Mini model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        848,
        896
      ],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-mini"
        },
        "options": {}
      },
      "credentials": {
        "openAiApi": {
          "id": "dMiSy27YCK6c6rra",
          "name": "Duv's OpenAI"
        }
      },
      "typeVersion": 1.2
    },
    {
      "id": "834eb57c-ded3-46f9-8912-2a323f1f091f",
      "name": "Large model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        1584,
        896
      ],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1",
          "cachedResultName": "gpt-4.1"
        },
        "options": {}
      },
      "credentials": {
        "openAiApi": {
          "id": "dMiSy27YCK6c6rra",
          "name": "Duv's OpenAI"
        }
      },
      "typeVersion": 1.2
    },
    {
      "id": "4e006500-9e61-45e3-bb20-28cf342667a8",
      "name": "RAG via Lookio",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        1216,
        704
      ],
      "parameters": {
        "url": "=https://api.lookio.app/webhook/query",
        "method": "POST",
        "options": {},
        "sendBody": true,
        "sendHeaders": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{ $json.text }}"
            },
            {
              "name": "assistant_id",
              "value": "<YOUR-ASSISTANT-ID>"
            },
            {
              "name": "query_mode",
              "value": "flash"
            }
          ]
        },
        "headerParameters": {
          "parameters": [
            {
              "name": "api_key",
              "value": "<YOUR-API-KEY>"
            }
          ]
        }
      },
      "typeVersion": 4.2
    },
    {
      "id": "d90f9ab0-5dd5-46ef-a87a-83f3e077fab9",
      "name": "Intent router",
      "type": "@n8n/n8n-nodes-langchain.textClassifier",
      "position": [
        400,
        496
      ],
      "parameters": {
        "options": {
          "systemPromptTemplate": "=Please classify the text provided by the user into one of the following categories: {categories}, and use the provided formatting instructions below. Don't explain, and only output the json.\n\n\nNB: Here are the previous messages from the conversation that came before this new text to categorize - focus on the new text to categorize though, this is just some context:\n\n{{ \n  $json.messages\n    .map(m => `human: ${m.human}\\nai: ${m.ai}`)\n    .join('\\n')\n}}"
        },
        "inputText": "={{ $('When chat message received').item.json.chatInput }}",
        "categories": {
          "categories": [
            {
              "category": "=No knowledge retrieval needed to answer this query",
              "description": "=Use this category when the message can be answered directly without consulting any external knowledge or documentation. This includes greetings, confirmations, small talk (e.g., \"hi\", \"hello\", \"thanks\", \"ok\")."
            },
            {
              "category": "=Knowledge retrieval is needed to answer this query",
              "description": "=Use this category when the message requires knowledge to be answered. Good use cases are when the user asks questions."
            }
          ]
        }
      },
      "typeVersion": 1.1
    },
    {
      "id": "f83304af-f74a-4aed-8a64-d7b657a9abaa",
      "name": "Respond to Chat",
      "type": "@n8n/n8n-nodes-langchain.chat",
      "position": [
        1904,
        496
      ],
      "parameters": {
        "message": "={{ $json.text }}",
        "options": {
          "memoryConnection": false
        },
        "waitUserReply": false
      },
      "typeVersion": 1
    },
    {
      "id": "e89d675e-eac6-4e95-9238-d7b3501e1b2d",
      "name": "Find past messages",
      "type": "@n8n/n8n-nodes-langchain.memoryManager",
      "position": [
        48,
        496
      ],
      "parameters": {
        "options": {}
      },
      "typeVersion": 1.1
    },
    {
      "id": "735ad901-9c58-4851-bf1b-d93aaf46d557",
      "name": "Simple Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "position": [
        208,
        720
      ],
      "parameters": {},
      "typeVersion": 1.3
    },
    {
      "id": "e1f44ef4-86c7-428b-8e6c-cc35d3181123",
      "name": "Store messages",
      "type": "@n8n/n8n-nodes-langchain.memoryManager",
      "position": [
        2128,
        496
      ],
      "parameters": {
        "mode": "insert",
        "messages": {
          "messageValues": [
            {
              "type": "user",
              "message": "={{ $('When chat message received').item.json.chatInput }}"
            },
            {
              "type": "ai",
              "message": "={{ $json.text }}"
            }
          ]
        }
      },
      "typeVersion": 1.1
    },
    {
      "id": "61bf6661-fb9b-4179-b2b7-52f66c13cd39",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1136,
        672
      ],
      "parameters": {
        "color": 3,
        "width": 256,
        "height": 320,
        "content": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Action required\n\nMake sure to set your Lookio API key and workspace ID in here."
      },
      "typeVersion": 1
    },
    {
      "id": "5a21675c-622b-48d5-b076-3c30eb861811",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -736,
        224
      ],
      "parameters": {
        "width": 432,
        "height": 576,
        "content": "# **Smart & Efficient RAG Chatbot**\n\nThis workflow optimizes AI costs and speed by using an **Intent Router** pattern. \n\nInstead of one big model doing everything, it routes simple chats to small models and saves the heavy-duty LLMs for complex knowledge retrieval via **Lookio**.\n\n## **How to use**\n1.  **Connect AI:** Add credentials to the three **OpenAI Language Model** nodes.\n2.  **Configure Lookio:** In the **RAG via Lookio** node, replace the placeholders with your **API Key** and **Assistant ID** from [Lookio.app](https://www.lookio.app/).\n3.  **Test:** Use the chat window to ask questions about your uploaded documents.\n\n**Note:** For more logic on how to break down agents into modular steps, watch [this video guide](https://www.youtube.com/watch?v=BHdJFnx2wrc).\n\n*A template created by Guillaume Duvernay*"
      },
      "typeVersion": 1
    },
    {
      "id": "d7dde290-e168-4dd2-b6fd-5b1ee6a592bd",
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -240,
        368
      ],
      "parameters": {
        "color": 7,
        "width": 582,
        "height": 320,
        "content": "## 1. Receive user message & load the conversation"
      },
      "typeVersion": 1
    },
    {
      "id": "744c2765-8163-4e99-bc8c-36d83cf659ab",
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        352,
        368
      ],
      "parameters": {
        "color": 7,
        "width": 374,
        "height": 320,
        "content": "## 2. AI confirms if powerful RAG is needed"
      },
      "typeVersion": 1
    },
    {
      "id": "9275c57e-f39a-4a29-bf23-0bf5082df61c",
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        896,
        208
      ],
      "parameters": {
        "color": 7,
        "width": 374,
        "height": 256,
        "content": "## 3.1. writing a simple response"
      },
      "typeVersion": 1
    },
    {
      "id": "37947331-e585-4f8e-ad43-90a2449a4458",
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        752,
        608
      ],
      "parameters": {
        "color": 7,
        "width": 1046,
        "height": 432,
        "content": "## 3.2. Writing an AI knowledge retrieval based response"
      },
      "typeVersion": 1
    },
    {
      "id": "16863033-491b-47df-9da3-ef4f190569d1",
      "name": "Sticky Note6",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1840,
        400
      ],
      "parameters": {
        "color": 7,
        "width": 598,
        "height": 272,
        "content": "## 4. Response handling"
      },
      "typeVersion": 1
    }
  ],
  "connections": {
    "Mini model": {
      "ai_languageModel": [
        [
          {
            "node": "Prepare retrieval query",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Large model": {
      "ai_languageModel": [
        [
          {
            "node": "Write the final response",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Intent router": {
      "main": [
        [
          {
            "node": "Simple response",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Prepare retrieval query",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Simple Memory": {
      "ai_memory": [
        [
          {
            "node": "Find past messages",
            "type": "ai_memory",
            "index": 0
          },
          {
            "node": "Store messages",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "RAG via Lookio": {
      "main": [
        [
          {
            "node": "Write the final response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Store messages": {
      "main": [
        []
      ]
    },
    "Respond to Chat": {
      "main": [
        [
          {
            "node": "Store messages",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Simple response": {
      "main": [
        [
          {
            "node": "Respond to Chat",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Very small model": {
      "ai_languageModel": [
        [
          {
            "node": "Simple response",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Intent router",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Find past messages": {
      "main": [
        [
          {
            "node": "Intent router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare retrieval query": {
      "main": [
        [
          {
            "node": "RAG via Lookio",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Write the final response": {
      "main": [
        [
          {
            "node": "Respond to Chat",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "Find past messages",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "meta": {
    "site": "https://github.com/zengfr/n8n-workflow-all-templates",
    "name": "Build a cost-efficient Lookio RAG chatbot with GPT-4.1 models for knowledge Q&A",
    "wechat": "youandme10086",
    "id": 12521,
    "update_time": "2026-02-13"
  }
}