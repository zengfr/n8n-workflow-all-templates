{
  "id": "ZHd8MYVLT1HaPeiY",
  "meta": {
    "site": "https://github.com/zengfr/n8n-workflow-all-templates",
    "name": "Ask questions about past meetings using voice with OpenAI and Pinecone",
    "wechat": "youandme10086",
    "id": 12757,
    "update_time": "2026-02-13"
  },
  "name": "Ask your meetings questions using voice and AI",
  "tags": [],
  "nodes": [
    {
      "id": "e6b8eceb-d021-498b-9e39-ed04611c1899",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1200,
        1408
      ],
      "parameters": {
        "color": 7,
        "width": 720,
        "height": 384,
        "content": "### Voice Input Handling\n\nThis workflow starts by receiveing an audio file containing the user’s spoken question and then it converts the audio question into readable text using OpenAI and extracts the spoken question text safely."
      },
      "typeVersion": 1
    },
    {
      "id": "798768d3-6daf-4f88-8a7d-624e7e949f75",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1952,
        1408
      ],
      "parameters": {
        "color": 7,
        "width": 576,
        "height": 560,
        "content": "### Vector Search (RAG)\n\nConverts the question into a vector for semantic search and searches meeting data using the team namespace then combines multiple Pinecone results into one clean context block."
      },
      "typeVersion": 1
    },
    {
      "id": "899a0e30-67b4-4b9b-ab2e-ba49b2d84e5c",
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        2560,
        1408
      ],
      "parameters": {
        "color": 7,
        "width": 592,
        "height": 560,
        "content": "### AI Answer Generation\n\nThe ai agent answers the question using only the retrieved meeting context and generates a short, clear, factual response."
      },
      "typeVersion": 1
    },
    {
      "id": "36fcbf9a-1171-48ac-9965-6a6606b17124",
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3200,
        1424
      ],
      "parameters": {
        "color": 7,
        "width": 480,
        "height": 384,
        "content": "### Voice Response Output\n\nConverts the AI’s text answer into spoken audio and sends the audio answer back to the user."
      },
      "typeVersion": 1
    },
    {
      "id": "37c9b880-4ec0-4de9-8c28-c0caf1102dd7",
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        672,
        832
      ],
      "parameters": {
        "width": 480,
        "height": 560,
        "content": "## Workflow Overview\n\nThis is a voice-activated meeting assistant workflow. It allows users to ask questions using their voice. The workflow searches past meeting notes stored in Pinecone and replies with a spoken answer.\n\n### How it works\n\nThe user sends a voice question to the webhook. The audio is converted into text using speech transcription by Open AI. The question text is cleaned and prepared for searching. Pinecone is then used to search relevant meeting notes. The AI generates an answer using only the retrieved meeting context. The answer is converted into speech. Finally, the audio response is sent back to the user.\n\n\n### Setup\n\nOpenAI API (for transcription, embeddings, speech)\nAzure OpenAI (for chat responses)\nPinecone API (vector database access)"
      },
      "typeVersion": 1
    },
    {
      "id": "8fc20e2c-f4ee-4af6-9ad6-534e09521a2a",
      "name": "Receive Voice Question",
      "type": "n8n-nodes-base.webhook",
      "position": [
        1248,
        1584
      ],
      "webhookId": "5489abc5-0310-416c-b84b-82cd652d1872",
      "parameters": {
        "path": "meeting-sentiment-query",
        "options": {
          "binaryData": false
        },
        "httpMethod": "POST",
        "responseMode": "responseNode"
      },
      "typeVersion": 1
    },
    {
      "id": "ed6126b7-815e-449f-90de-22db161ec183",
      "name": "Transcribe Voice Question",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "position": [
        1520,
        1584
      ],
      "parameters": {
        "options": {},
        "resource": "audio",
        "operation": "transcribe",
        "binaryPropertyName": "file"
      },
      "credentials": {
        "openAiApi": {
          "id": "5Kzt6hGSZ1JHZqWN",
          "name": "OpenAi account 2"
        }
      },
      "typeVersion": 2.1
    },
    {
      "id": "e4aea8a4-93d4-428f-b0ca-736efd9c0f41",
      "name": "Extract Voice Question",
      "type": "n8n-nodes-base.code",
      "position": [
        1776,
        1584
      ],
      "parameters": {
        "jsCode": "// Extract the transcribed voice question\nif (!$json.text || typeof $json.text !== 'string') {\n  throw new Error('Voice question text not found');\n}\n\nreturn [\n  {\n    json: {\n      question: $json.text,\n      team: $json.team || 'Test Team'\n    }\n  }\n];\n"
      },
      "typeVersion": 2
    },
    {
      "id": "df728f04-0e65-41b0-ba59-2f9f1f87189e",
      "name": "Generate Question Embedding",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "position": [
        2032,
        1808
      ],
      "parameters": {
        "options": {}
      },
      "credentials": {
        "openAiApi": {
          "id": "5Kzt6hGSZ1JHZqWN",
          "name": "OpenAi account 2"
        }
      },
      "typeVersion": 1.2
    },
    {
      "id": "3c7a80ea-877d-4c97-8742-184bf6769796",
      "name": "Search Meetings in Pinecone",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "position": [
        2032,
        1584
      ],
      "parameters": {
        "mode": "load",
        "prompt": "={{ $json.team }}",
        "options": {
          "pineconeNamespace": "={{ $json.team }}"
        },
        "pineconeIndex": {
          "__rl": true,
          "mode": "list",
          "value": "meeting-sentiment-index"
        }
      },
      "credentials": {
        "pineconeApi": {
          "id": "AYsRvXPdrinjeW4A",
          "name": "PineconeApi account 2"
        }
      },
      "typeVersion": 1.3
    },
    {
      "id": "5b866ce9-be8d-47e6-871a-d60fb8e73907",
      "name": "Build Meeting Context",
      "type": "n8n-nodes-base.code",
      "position": [
        2368,
        1584
      ],
      "parameters": {
        "jsCode": "const items = $input.all();\n\nif (!items.length) {\n  throw new Error('No documents returned from Pinecone');\n}\n\nconst context = items\n  .map(item => item.json.document?.pageContent)\n  .filter(Boolean)\n  .join('\\n---\\n');\n\nreturn [\n  {\n    json: {\n      context\n    }\n  }\n];\n"
      },
      "typeVersion": 2
    },
    {
      "id": "13af4da5-b10f-4f07-bf11-cb9b1c0b3cd0",
      "name": "Answer Question from Meetings",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        2624,
        1584
      ],
      "parameters": {
        "text": "=You are a voice-enabled meeting assistant.\n\nAnswer the user's question using ONLY the provided meeting context.\nIf the answer is not found, say you don’t have that information.\nKeep answers short and clear.\n\n\nMeeting context:\n{{ $json.context }}\n\nUser question:\n{{ $('Extract Voice Question').item.json.question }}\n\n",
        "options": {},
        "promptType": "define"
      },
      "typeVersion": 3
    },
    {
      "id": "e6a6283b-db04-48f4-938b-c04163994f11",
      "name": "AI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatAzureOpenAi",
      "position": [
        2624,
        1808
      ],
      "parameters": {
        "model": "GPT-4O-MINI",
        "options": {}
      },
      "credentials": {
        "azureOpenAiApi": {
          "id": "C3WzT18XqF8OdVM6",
          "name": "Azure Open AI account"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "bf92cc41-fd87-46e2-9485-4fcbe7746c42",
      "name": "Prepare Answer for Audio",
      "type": "n8n-nodes-base.code",
      "position": [
        3008,
        1584
      ],
      "parameters": {
        "jsCode": "// Loop over input items and add a new field called 'myNewField' to the JSON of each one\nfor (const item of $input.all()) {\n  item.json.myNewField = 1;\n}\n\nreturn $input.all();"
      },
      "typeVersion": 2
    },
    {
      "id": "c04e79cc-c599-441f-968f-3ef1347d802d",
      "name": "Generate Spoken Answer",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "position": [
        3280,
        1584
      ],
      "parameters": {
        "input": "={{ $json.output }}",
        "options": {},
        "resource": "audio"
      },
      "credentials": {
        "openAiApi": {
          "id": "5Kzt6hGSZ1JHZqWN",
          "name": "OpenAi account 2"
        }
      },
      "typeVersion": 2.1
    },
    {
      "id": "b1ea0722-f6b7-4629-a5e6-64790d3a8f68",
      "name": "Return Audio Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "position": [
        3488,
        1584
      ],
      "parameters": {
        "options": {}
      },
      "typeVersion": 1.5
    }
  ],
  "active": false,
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "6904a792-26b6-4495-832a-42651e336b99",
  "connections": {
    "AI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Answer Question from Meetings",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Build Meeting Context": {
      "main": [
        [
          {
            "node": "Answer Question from Meetings",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Voice Question": {
      "main": [
        [
          {
            "node": "Search Meetings in Pinecone",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Spoken Answer": {
      "main": [
        [
          {
            "node": "Return Audio Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Receive Voice Question": {
      "main": [
        [
          {
            "node": "Transcribe Voice Question",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Answer for Audio": {
      "main": [
        [
          {
            "node": "Generate Spoken Answer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Transcribe Voice Question": {
      "main": [
        [
          {
            "node": "Extract Voice Question",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Generate Question Embedding": {
      "ai_embedding": [
        [
          {
            "node": "Search Meetings in Pinecone",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Search Meetings in Pinecone": {
      "main": [
        [
          {
            "node": "Build Meeting Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Answer Question from Meetings": {
      "main": [
        [
          {
            "node": "Prepare Answer for Audio",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  }
}