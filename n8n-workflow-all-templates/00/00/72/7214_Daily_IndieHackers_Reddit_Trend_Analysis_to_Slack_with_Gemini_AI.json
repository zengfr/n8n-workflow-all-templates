{
  "meta": {
    "site": "https://github.com/zengfr/n8n-workflow-all-templates",
    "name": "Daily IndieHackers Reddit Trend Analysis to Slack with Gemini AI",
    "wechat": "youandme10086",
    "id": 7214,
    "update_time": "2025-11-10"
  },
  "nodes": [
    {
      "id": "d56d56ef-e47d-4662-8fcc-61d658e33266",
      "name": "Daily Schedule",
      "type": "n8n-nodes-base.cron",
      "position": [
        384,
        272
      ],
      "parameters": {
        "triggerTimes": {
          "item": [
            {
              "hour": 8
            }
          ]
        }
      },
      "typeVersion": 1
    },
    {
      "id": "91fa23ab-325d-455e-b8a2-41d4be6df8e0",
      "name": "Extract Posts Data",
      "type": "n8n-nodes-base.code",
      "position": [
        784,
        272
      ],
      "parameters": {
        "jsCode": "// Loop over input items and add a new field called 'myNewField' to the JSON of each one\nfor (const item of $input.all()) {\n  item.json.myNewField = 1;\n}\n\nreturn $input.all();"
      },
      "typeVersion": 2
    },
    {
      "id": "c88ba66a-591a-4ade-9c82-40e37109c455",
      "name": "AI Intent Analysis",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "position": [
        992,
        160
      ],
      "parameters": {
        "modelId": {
          "__rl": true,
          "mode": "list",
          "value": "models/gemini-2.5-flash-lite-preview-06-17",
          "cachedResultName": "models/gemini-2.5-flash-lite-preview-06-17"
        },
        "options": {
          "temperature": 0.3
        },
        "messages": {
          "values": [
            {
              "role": "model",
              "content": "=You are an expert analyst for startup communities who identifies hot topics, growth patterns, and actionable insights from Reddit posts, focusing on indie hackers and solopreneurs."
            },
            {
              "content": "=You are given an array of Reddit posts from r/indiehackers in JSON format. Each object includes fields like title, selftext, ups, num_comments, created_utc, link_flair_text, and url. Perform a structured analysis to identify what is hot and why. Use only the provided data. Do not invent data.\n\nTasks\n\nData sanity\n\nParse the JSON array and treat each object as a post.\n\nUse these fields when available: title, selftext, ups, score, upvote_ratio, num_comments, created_utc, link_flair_text, author, subreddit_subscribers, permalink, url.\n\nIf values are null or missing, handle gracefully.\n\nHotness scoring\n\nCompute a relative Hotness Score for each post to normalize by time and engagement:\nHotness Score = (ups + 2*num_comments) * freshness_decay\nwhere freshness_decay = 1 / (1 + hours_since_post/24)\n\nIf created_utc is not comparable, assume the freshest post has hours_since_post=1 and scale others proportionally.\n\nOutput Hotness Score to one decimal place.\n\nTopic extraction\n\nExtract concise topics using title+first 500 chars of selftext.\n\nPrefer 1-5 word topics, e.g., ‚ÄúMod recruitment,‚Äù ‚ÄúSaaS boilerplate sales,‚Äù ‚ÄúCompetitor paywalls research,‚Äù ‚ÄúCold email performance,‚Äù ‚ÄúData visualization SaaS.‚Äù\n\nAssign 1‚Äì3 topics per post.\n\nTheme clustering\n\nGroup posts into higher-level themes and count frequency and total Hotness by theme.\n\nExample themes: Go-to-market tactics, Product launches, Community/Moderation, Tooling/Boilerplates, Growth/Distribution, Monetization/Pricing, Research/Validation.\n\nSignals of traction\n\nFor each post, extract any concrete traction signals (metrics, revenue, sales, subscribers, conversion, demos booked).\n\nPresent as short bullet points tied to the post.\n\nActionable insights\n\nDerive 3‚Äì7 actionable insights for indie hackers based on patterns in high-heat posts (what to build, how to launch, which channels work, what content resonates).\n\nMake each insight specific and testable (Who, What, How, Expected signal).\n\nOutput format\nReturn the following sections:\n\nHot posts (ranked)\nFor each top 5 posts by Hotness Score:\n\nRank. Title (Hotness: X.X)\n\nTopics: ‚Ä¶\n\nFlair: ‚Ä¶\n\nEngagement: ups=, comments=, upvote_ratio=\n\nPosted: created_utc (as UNIX)\n\nTraction signals: bullets or ‚ÄúNone stated‚Äù\n\nLink: permalink\n\nThemes summary\n\nTheme name ‚Äî posts: N, total hotness: X.X\n\nOne-line takeaway per theme\n\nWhat‚Äôs working now (actionable insights)\n\n5‚Äì7 bullets with concrete experiments\n\nEmerging opportunities\n\n3‚Äì5 bullets identifying underserved needs or repeated pain points\n\nData appendix\n\nBrief note on scoring formula and any assumptions used\n\nConstraints\n\nDo not fetch external data; analyze only provided JSON.\n\nKeep the final output under 600 words.\n\nBe concise, avoid repetition, and prefer clear, skimmable bullets.\n\nNow analyze this dataset:\n{{ JSON.stringify($json, null, 10) }}"
            }
          ]
        }
      },
      "credentials": {
        "googlePalmApi": {
          "id": "WXBzegbf5JJGseFg",
          "name": "Google Gemini(PaLM) Api account 2"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "65c2f7e8-d25f-428b-bc7a-d77715404155",
      "name": "Parse AI Response",
      "type": "n8n-nodes-base.code",
      "position": [
        1424,
        160
      ],
      "parameters": {
        "jsCode": "// Loop over input items and add a new field called 'myNewField' to the JSON of each one\nfor (const item of $input.all()) {\n  item.json.myNewField = 1;\n}\n\nreturn $input.all();"
      },
      "typeVersion": 2
    },
    {
      "id": "660c8c3e-312a-4e48-8e97-a5bd80c0f82d",
      "name": "Send to Slack",
      "type": "n8n-nodes-base.slack",
      "onError": "continueRegularOutput",
      "position": [
        2096,
        160
      ],
      "webhookId": "de5cfe06-2dd4-45fb-9d8b-fcba2cac25f1",
      "parameters": {
        "text": "={{ $json.content.parts[0].text }}",
        "select": "channel",
        "channelId": {
          "__rl": true,
          "mode": "list",
          "value": "C098Y3YJC3C",
          "cachedResultName": "product-ai"
        },
        "otherOptions": {
          "mrkdwn": true
        },
        "authentication": "oAuth2"
      },
      "credentials": {
        "slackOAuth2Api": {
          "id": "i1bKyxInTqS4wicG",
          "name": "Slack account 3"
        }
      },
      "typeVersion": 2.3
    },
    {
      "id": "4c8435df-f386-4939-9758-60cfd0b15afc",
      "name": "Get many posts",
      "type": "n8n-nodes-base.reddit",
      "position": [
        592,
        272
      ],
      "parameters": {
        "limit": 5,
        "filters": {},
        "operation": "getAll",
        "subreddit": "indiehackers"
      },
      "credentials": {
        "redditOAuth2Api": {
          "id": "483pkfYlMMvnnZcG",
          "name": "Reddit account 2"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "85d5af69-f320-47c0-b7c4-5d21060dc8b0",
      "name": "Groq Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "position": [
        1632,
        384
      ],
      "parameters": {
        "model": "openai/gpt-oss-120b",
        "options": {}
      },
      "credentials": {
        "groqApi": {
          "id": "kMzS3MA3i9DkfPCw",
          "name": "Groq account 2"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "8b53096c-c429-432f-9b97-d1a511b81de9",
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        1696,
        160
      ],
      "parameters": {
        "text": "=Input\n\nposts: JSON array of Reddit posts from r/indiehackers.\n\ncontext:\n\nchannel_type: one of [company, team, project].\n\naudience: string describing who should read this.\n\ncta_link: URL for the full analysis or dashboard.\n\ntimeframe_label: human label for the period (e.g., ‚ÄúThis week‚Äù).\n\nask_in_thread_note: short text inviting questions in thread.\n\nTasks\n\nParse and validate\n\nTreat each array element as a post.\n\nUse available fields: title, selftext, ups, num_comments, upvote_ratio, created_utc, link_flair_text, permalink, url, score, subreddit_subscribers, author.\n\nHandle nulls gracefully.\n\nScore hotness\n\nHotness = (ups + 2*num_comments) * freshness_decay\n\nfreshness_decay = 1 / (1 + hours_since_post/24)\n\nIf absolute time unavailable, scale freshness so newest post has hours_since_post=1, others proportional.\n\nRound Hotness to 1 decimal.\n\nExtract topics and traction\n\nTopics: 1‚Äì3 concise phrases (1‚Äì5 words) from title+first 500 chars of selftext.\n\nTraction: any concrete metrics (sales, revenue, demos, reply rates, etc.). If none, ‚ÄúNone stated.‚Äù\n\nCluster into themes\n\nThemes like: Go-to-market, Product launches, Community/Moderation, Tooling/Boilerplates, Growth/Distribution, Monetization/Pricing, Research/Validation.\n\nFor each theme: count posts and sum Hotness.\n\nProduce Slack Block Kit JSON\n\nOutput MUST be a single JSON object with a top-level blocks array only (no attachments), valid per Block Kit.\n\nKeep the message compact and skimmable. Use:\n\nheader block for TL;DR headline.\n\nsection blocks with mrkdwn for summaries.\n\nfields for compact stats.\n\ncontext block for disclaimers or timestamps.\n\nactions block with one ‚ÄúOpen Dashboard‚Äù button if cta_link provided.\n\nUse minimal, meaningful emojis (1‚Äì3 per section).\n\nInvite discussion in a thread with a short line.\n\nSlack content rules\n\nHeadline (TL;DR): bold, 1‚Äì2 emojis. Example: ‚ÄúüöÄ Indie Hackers Trends ‚Äî This Week‚Äù.\n\nCore info first: one sentence summary of the biggest takeaway this period.\n\nHot posts: top 3 posts by Hotness. Each includes title, Hotness, topics, flair, key engagement, traction, and a Reddit button.\n\nThemes summary: top 3 themes with posts count and total hotness and a one‚Äëline takeaway.\n\nCTA: a single bold CTA to view the dashboard/report.\n\nThread prompt: ‚ÄúPlease ask questions in the thread üëá‚Äù.\n\nInclude a small ‚Äúhow scored‚Äù note in context.\n\nKeep total blocks under 50; aim for brief content.\n\nRequired output schema\nReturn ONLY a JSON object with this structure:\n\n{\n\"blocks\": [\n{\n\"type\": \"header\",\n\"text\": { \"type\": \"plain_text\", \"text\": \"üöÄ Indie Hackers Trends ‚Äî {timeframe_label}\", \"emoji\": true }\n},\n{\n\"type\": \"section\",\n\"text\": {\n\"type\": \"mrkdwn\",\n\"text\": \"TL;DR: {single_sentence_big_takeaway}\"\n}\n},\n{\n\"type\": \"section\",\n\"fields\": [\n{ \"type\": \"mrkdwn\", \"text\": \"Audience:\\n{audience}\" },\n{ \"type\": \"mrkdwn\", \"text\": \"Posts analyzed:\\n{posts_count}\" }\n]\n},\n\ntext\n{ \"type\": \"divider\" },\n\n{\n  \"type\": \"section\",\n  \"text\": { \"type\": \"mrkdwn\", \"text\": \"*üî• Hot Posts (Top 3)*\" }\n},\n\n// Repeat this group for up to 3 posts\n{\n  \"type\": \"section\",\n  \"text\": {\n    \"type\": \"mrkdwn\",\n    \"text\": \"*{rank}\\\\. {title}*  \\nHotness: {hotness}\"\n  }\n},\n{\n  \"type\": \"context\",\n  \"elements\": [\n    { \"type\": \"mrkdwn\", \"text\": \"*Topics:* {topics_csv}\" },\n    { \"type\": \"mrkdwn\", \"text\": \"*Flair:* {flair_or_dash}\" }\n  ]\n},\n{\n  \"type\": \"section\",\n  \"fields\": [\n    { \"type\": \"mrkdwn\", \"text\": \"*Ups:*\\n{ups_or_dash}\" },\n    { \"type\": \"mrkdwn\", \"text\": \"*Comments:*\\n{num_comments_or_dash}\" },\n    { \"type\": \"mrkdwn\", \"text\": \"*Upvote ratio:*\\n{upvote_ratio_or_dash}\" },\n    { \"type\": \"mrkdwn\", \"text\": \"*Posted (UNIX):*\\n{created_utc_or_dash}\" }\n  ]\n},\n{\n  \"type\": \"section\",\n  \"text\": { \"type\": \"mrkdwn\", \"text\": \"*Traction:*\\n{traction_bullets_or_None_stated}\" }\n},\n{\n  \"type\": \"actions\",\n  \"elements\": [\n    {\n      \"type\": \"button\",\n      \"text\": { \"type\": \"plain_text\", \"text\": \"Open Reddit\" },\n      \"url\": \"https://www.reddit.com{permalink}\"\n    }\n  ]\n},\n\n{ \"type\": \"divider\" },\n\n{\n  \"type\": \"section\",\n  \"text\": { \"type\": \"mrkdwn\", \"text\": \"*üß≠ Themes Summary*\" }\n},\n\n// Up to 3 themes\n{\n  \"type\": \"section\",\n  \"text\": { \"type\": \"mrkdwn\", \"text\": \"- *{theme_name}* ‚Äî posts: {n}, total hotness: {sum_hotness}  \\n_{one_line_takeaway}_\" }\n},\n\n{ \"type\": \"divider\" },\n\n{\n  \"type\": \"section\",\n  \"text\": { \"type\": \"mrkdwn\", \"text\": \"*‚úÖ What to do now*\" }\n},\n{\n  \"type\": \"section\",\n  \"text\": { \"type\": \"mrkdwn\", \"text\": \"- {actionable_insight_1}\\n- {actionable_insight_2}\\n- {actionable_insight_3}\" }\n},\n\n{\n  \"type\": \"actions\",\n  \"elements\": [\n    {\n      \"type\": \"button\",\n      \"text\": { \"type\": \"plain_text\", \"text\": \"Open Dashboard\" },\n      \"url\": \"{cta_link}\"\n    }\n  ]\n},\n\n{\n  \"type\": \"context\",\n  \"elements\": [\n    { \"type\": \"mrkdwn\", \"text\": \"_Please ask questions in the thread üëá  -   Hotness = (ups + 2√ócomments) √ó 1/(1 + hours/24)_\" }\n  ]\n}\n]\n}\n\nConstraints\n\nOutput only the JSON object above (no extra text).\n\nUse mrkdwn and fields per Slack docs.\n\nKeep emojis purposeful and minimal.\n\nButtons must be valid Block elements.\n\nDo not exceed 50 blocks.\n\nNow analyze this dataset and produce the Slack JSON:\n\nposts: [PASTE JSON ARRAY HERE]\n\ncontext:\n{\n\"channel_type\": \"team\",\n\"audience\": \"Growth, Product, and Founders\",\n\"cta_link\": \"https://example.com/trends-dashboard\",\n\"timeframe_label\": \"This Week\",\n\"ask_in_thread_note\": \"Please ask any questions in the thread üëá\"\n}\n\n{{ JSON.stringify($json, null, 2) }}",
        "options": {
          "systemMessage": "You are a startup community analyst and Slack content designer. Produce a single Slack Block Kit message that helps a team quickly understand what‚Äôs trending and what to do next. The message should be skimmable, well-structured, and intera"
        },
        "promptType": "define"
      },
      "typeVersion": 2.1
    },
    {
      "id": "da239eeb-8398-4318-8361-e483e30ec70c",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -224,
        -512
      ],
      "parameters": {
        "width": 560,
        "height": 1424,
        "content": "# üöÄ Daily IndieHackers Reddit Trend Analysis to Slack\n\n> **Transform Reddit chaos into actionable startup intelligence**  \n> Get AI-powered insights from r/indiehackers delivered to your Slack every morning\n\n## üõ†Ô∏è Requirements\n\nYou'll need API access for: **Reddit** (OAuth2), **Google Gemini**, **Groq**, and **Slack** (OAuth2). All have free tiers available.\n\n---\n\n## üöÄ Setup Guide\n\n### 1Ô∏è‚É£ Configure Your Credentials\n\nAdd these credentials in n8n: **Reddit OAuth2**, **Google Gemini**, **Groq**, and **Slack OAuth2**. The workflow will guide you through each setup.\n\n### 2Ô∏è‚É£ Customize the Schedule\n\n**Default:** Daily at 8:00 AM  \n**To modify:** Edit the \"Daily Schedule\" cron trigger node\n\n```javascript\n// Example: Run at 9:30 AM\n{\n  \"triggerTimes\": {\n    \"item\": [{ \"hour\": 9, \"minute\": 30 }]\n  }\n}\n```\n\n### 3Ô∏è‚É£ Set Your Slack Destination\n\n1. Open the **\"Send to Slack\"** node\n2. Select your target channel\n3. Configure notification preferences\n\n### 4Ô∏è‚É£ Adjust Analysis Parameters\n\n**Post Limit:** Change from default 5 posts\n```javascript\n// In \"Get many posts\" Reddit node\n\"limit\": 10  // Recommended: 3-10 posts\n```\n\n**Context Customization:**\n```json\n{\n  \"channel_type\": \"team\",\n  \"audience\": \"Growth, Product, and Founders\", \n  \"cta_link\": \"https://your-dashboard.com\",\n  \"timeframe_label\": \"This Week\"\n}\n```"
      },
      "typeVersion": 1
    }
  ],
  "pinData": {},
  "connections": {
    "AI Agent": {
      "main": [
        [
          {
            "node": "Send to Slack",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Daily Schedule": {
      "main": [
        [
          {
            "node": "Get many posts",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get many posts": {
      "main": [
        [
          {
            "node": "Extract Posts Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Groq Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Parse AI Response": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AI Intent Analysis": {
      "main": [
        [
          {
            "node": "Parse AI Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Posts Data": {
      "main": [
        [
          {
            "node": "AI Intent Analysis",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  }
}