{
  "id": "AwApYNYyap3QWQCh",
  "meta": {
    "site": "https://github.com/zengfr/n8n-workflow-all-templates",
    "name": "Implement Intelligent Message Buffering for AI Chats with Redis and GPT-4-mini",
    "wechat": "youandme10086",
    "id": 8238,
    "update_time": "2025-11-10"
  },
  "name": "Implementing a Scalable Message Buffer for Natural AI Conversations in n8n",
  "tags": [],
  "nodes": [
    {
      "id": "2f166c61-c613-46ef-9d58-d24873c6a477",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -1408,
        -64
      ],
      "parameters": {
        "color": 5,
        "width": 380,
        "height": 724,
        "content": "## üöÄ Welcome to the Scalable Chat Buffer Workflow!\n\nThis workflow solves a common problem in AI chat implementations: handling multiple rapid messages from users naturally.\n\n### üéØ What it does:\n- **Buffers** rapid messages from users (like when someone types multiple lines quickly)\n- **Aggregates** them into a single context\n- **Processes** everything together for more natural AI responses\n- **Scales** efficiently for multiple concurrent users\n\n### üìã Prerequisites:\n1. **Redis** connection configured\n2. **OpenAI API** key (or other LLM provider)\n3. **n8n version** 1.0.0 or higher\n\n### ‚öôÔ∏è Configuration:\n1. Set up your Redis credentials\n2. Configure your LLM provider\n3. Adjust the buffer timing (default: 15 seconds)\n4. Deploy and test!\n\n### üí° Key Innovation:\nUnlike traditional approaches, only the FIRST message in a sequence waits. Subsequent messages skip the queue, eliminating bottlenecks!"
      },
      "typeVersion": 1
    },
    {
      "id": "d09b934e-a97b-4e33-a34e-85044c7ab8ae",
      "name": "Sticky Note 1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -1008,
        528
      ],
      "parameters": {
        "width": 280,
        "height": 352,
        "content": "## üì• Message Entry Point\n\nThe **Chat Trigger** receives all incoming messages from users.\n\n**Session ID** is crucial - it ensures each user's messages are handled separately, enabling true parallel processing.\n\nDespite we are using the traditional chat trigger, this workflow will perform better using other chat triggers like Telegram and WhatsApp."
      },
      "typeVersion": 1
    },
    {
      "id": "983f720c-dde7-4ba1-847f-f10524aa4018",
      "name": "Sticky Note 2",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -752,
        80
      ],
      "parameters": {
        "color": 2,
        "width": 280,
        "height": 260,
        "content": "## üóÑÔ∏è Message Queue Insertion\n\nEach message is **pushed to a Redis list** specific to the user's session.\n\n**Key pattern**: `chat_{{sessionId}}`\n\nThis creates isolated message queues per conversation, preventing cross-talk between users."
      },
      "typeVersion": 1
    },
    {
      "id": "f38bceca-c322-4b22-9033-c9f48052510b",
      "name": "Sticky Note 3",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        128,
        -112
      ],
      "parameters": {
        "color": 4,
        "width": 320,
        "height": 372,
        "content": "## ‚è∞ Smart Waiting Logic\n\nThis is where the **magic happens**!\n\n**First message** in a burst:\n- Sets a timestamp\n- Enters a 15-second wait period\n- Allows time for additional messages\n\n**Subsequent messages**:\n- Skip the wait if within 15 seconds\n- Get added to the buffer immediately\n- No additional delays!\n\nThis eliminates the bottleneck that affects other buffer implementations."
      },
      "typeVersion": 1
    },
    {
      "id": "fe0c902c-995b-41ae-b322-9cf1d4dd844b",
      "name": "Sticky Note 4",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1040,
        -96
      ],
      "parameters": {
        "color": 3,
        "width": 320,
        "height": 348,
        "content": "## üîÑ Message Extraction & Context Building\n\nAfter the buffer period:\n1. **Extract** all messages from the Redis queue\n2. **Retrieve** any partial context from previous extraction\n3. **Concatenate** messages into a single context\n4. **Store** the combined message temporarily\n\nThis ensures all fragmented user thoughts are assembled before AI processing."
      },
      "typeVersion": 1
    },
    {
      "id": "df0d2487-ee4d-432d-8877-bcdf869eb28a",
      "name": "Sticky Note 5",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1648,
        -80
      ],
      "parameters": {
        "color": 6,
        "width": 320,
        "height": 336,
        "content": "## ü§ñ AI Agent Processing\n\nThe **AI Agent** receives the complete buffered message context:\n\n- Processes all user messages as one coherent input\n- Maintains conversation memory via Redis\n- Responds once with full understanding\n- Creates natural, human-like interactions\n\n**Result**: Instead of multiple fragmented responses, users get one thoughtful reply!"
      },
      "typeVersion": 1
    },
    {
      "id": "89b74088-597b-45d0-9bc2-de9f70647221",
      "name": "check_delay",
      "type": "n8n-nodes-base.if",
      "position": [
        576,
        272
      ],
      "parameters": {
        "options": {},
        "conditions": {
          "options": {
            "version": 2,
            "leftValue": "",
            "caseSensitive": true,
            "typeValidation": "strict"
          },
          "combinator": "and",
          "conditions": [
            {
              "id": "32ce777d-b762-4635-9618-c772bac2337b",
              "operator": {
                "type": "number",
                "operation": "lt"
              },
              "leftValue": "={{ $json.timestamp.toNumber() + 15 }}",
              "rightValue": "={{ $now.toSeconds() }}"
            }
          ]
        }
      },
      "typeVersion": 2.2
    },
    {
      "id": "e39363aa-5a75-4666-b8bf-0e2b4eb4df91",
      "name": "check_first_message",
      "type": "n8n-nodes-base.if",
      "position": [
        -320,
        368
      ],
      "parameters": {
        "options": {},
        "conditions": {
          "options": {
            "version": 2,
            "leftValue": "",
            "caseSensitive": true,
            "typeValidation": "strict"
          },
          "combinator": "and",
          "conditions": [
            {
              "id": "de69235c-bae4-4140-b47f-aff3a24b4be6",
              "operator": {
                "type": "number",
                "operation": "equals"
              },
              "leftValue": "={{ $json.values()[0] }}",
              "rightValue": 1
            }
          ]
        }
      },
      "typeVersion": 2.2
    },
    {
      "id": "1f0a5bf6-2a3e-422c-8210-aad82f9c867e",
      "name": "get_timestamp",
      "type": "n8n-nodes-base.redis",
      "position": [
        352,
        272
      ],
      "parameters": {
        "key": "=timestamp_{{ $('chat').first().json.sessionId }}",
        "keyType": "string",
        "options": {},
        "operation": "get",
        "propertyName": "timestamp"
      },
      "typeVersion": 1
    },
    {
      "id": "c7e250c9-98bf-45b6-9e50-c9567ff0b691",
      "name": "timestamp",
      "type": "n8n-nodes-base.redis",
      "position": [
        -96,
        272
      ],
      "parameters": {
        "key": "=timestamp_{{ $('chat').first().json.sessionId }}",
        "ttl": 25,
        "value": "={{ $now.toSeconds() }}",
        "expire": true,
        "keyType": "string",
        "operation": "set"
      },
      "typeVersion": 1
    },
    {
      "id": "9bf0ef1e-1d0d-499d-bcfb-05fd72be84a2",
      "name": "OpenAI Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        1696,
        496
      ],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4-mini"
        },
        "options": {
          "topP": 1,
          "temperature": 0.8,
          "frequencyPenalty": 0.8
        }
      },
      "typeVersion": 1.2
    },
    {
      "id": "a4f025ec-398c-491f-b260-20b2a0c25f9c",
      "name": "nothing",
      "type": "n8n-nodes-base.noOp",
      "position": [
        -96,
        464
      ],
      "parameters": {},
      "typeVersion": 1
    },
    {
      "id": "73504fdd-3fe1-453f-a6f4-16cf4cc8c775",
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        1696,
        272
      ],
      "parameters": {
        "text": "={{ $json.message }}",
        "options": {
          "systemMessage": "You are a helpful AI assistant. Respond naturally to the complete context of what the user is saying."
        },
        "promptType": "define"
      },
      "typeVersion": 2,
      "alwaysOutputData": true
    },
    {
      "id": "8d0fe1a5-0617-45cb-b254-c2d500d24526",
      "name": "redis_chat_memory",
      "type": "@n8n/n8n-nodes-langchain.memoryRedisChat",
      "position": [
        1824,
        496
      ],
      "parameters": {
        "sessionKey": "=memory_{{ $('chat').first().json.sessionId }}",
        "sessionTTL": 7200,
        "sessionIdType": "customKey"
      },
      "typeVersion": 1.5
    },
    {
      "id": "790ddc78-a3c7-4b31-ad1d-af6ca2ee978a",
      "name": "chat",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "position": [
        -992,
        368
      ],
      "webhookId": "chat-buffer-webhook",
      "parameters": {
        "options": {}
      },
      "typeVersion": 1.3
    },
    {
      "id": "ddbf7ea0-ed49-4c6b-a7bc-2a2cacfb043d",
      "name": "store",
      "type": "n8n-nodes-base.redis",
      "position": [
        -768,
        368
      ],
      "parameters": {
        "list": "=chat_{{ $json.sessionId }}",
        "operation": "push",
        "messageData": "={{ $json.chatInput }}"
      },
      "typeVersion": 1
    },
    {
      "id": "4c9a61a7-ec30-4ffc-ba1e-670fd2f0f0c2",
      "name": "count",
      "type": "n8n-nodes-base.redis",
      "position": [
        -544,
        368
      ],
      "parameters": {
        "key": "=counter_{{ $json.sessionId }}",
        "ttl": 25,
        "expire": true,
        "operation": "incr"
      },
      "typeVersion": 1
    },
    {
      "id": "42ca5892-fc88-4f91-9810-6997209f64e3",
      "name": "extract",
      "type": "n8n-nodes-base.redis",
      "position": [
        800,
        272
      ],
      "parameters": {
        "list": "=chat_{{ $('chat').first().json.sessionId }}",
        "tail": true,
        "options": {},
        "operation": "pop",
        "propertyName": "text"
      },
      "typeVersion": 1,
      "alwaysOutputData": true
    },
    {
      "id": "9285cfa5-5c37-4a43-bccb-37a5eb1d2027",
      "name": "wait",
      "type": "n8n-nodes-base.wait",
      "position": [
        128,
        272
      ],
      "webhookId": "wait-webhook",
      "parameters": {},
      "typeVersion": 1.1
    },
    {
      "id": "b75f167e-b117-4b90-9746-a24fc88763f4",
      "name": "get_message",
      "type": "n8n-nodes-base.redis",
      "position": [
        1024,
        272
      ],
      "parameters": {
        "key": "=message_{{ $('chat').first().json.sessionId }}",
        "keyType": "string",
        "options": {},
        "operation": "get",
        "propertyName": "message"
      },
      "typeVersion": 1
    },
    {
      "id": "7f405702-5983-431a-96fe-b04524c04ae4",
      "name": "set_message",
      "type": "n8n-nodes-base.redis",
      "position": [
        1248,
        272
      ],
      "parameters": {
        "key": "=message_{{ $('chat').first().json.sessionId }}",
        "ttl": 5,
        "value": "={{ $json.message ? $json.message : \"\" }}{{ $('extract').first().json.text }}\n",
        "expire": true,
        "keyType": "string",
        "operation": "set"
      },
      "typeVersion": 1
    },
    {
      "id": "403218e5-4032-4947-b8ca-c336a88fbb4d",
      "name": "check_queue_is_empty",
      "type": "n8n-nodes-base.if",
      "position": [
        1472,
        272
      ],
      "parameters": {
        "options": {},
        "conditions": {
          "options": {
            "version": 2,
            "leftValue": "",
            "caseSensitive": true,
            "typeValidation": "strict"
          },
          "combinator": "and",
          "conditions": [
            {
              "id": "db8d3308-4158-423c-817e-b55786bc13ca",
              "operator": {
                "type": "string",
                "operation": "empty",
                "singleValue": true
              },
              "leftValue": "={{ $('extract').first().json.text }}",
              "rightValue": "={{ $json.values()[0] }}"
            }
          ]
        }
      },
      "typeVersion": 2.2
    },
    {
      "id": "250117dc-ae26-4ea2-b782-a581ad2b8790",
      "name": "Sticky Note 6",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -416,
        592
      ],
      "parameters": {
        "color": 7,
        "width": 328,
        "height": 312,
        "content": "## üîç Critical Decision Points\n\nThese **IF nodes** control the flow:\n\n1. **check_first_message**: Is this the first message from this session?\n2. **check_delay**: Has the buffer period expired?\n3. **check_queue_is_empty**: Are there messages ready to process?\n\nThese decisions ensure efficient, scalable message handling."
      },
      "typeVersion": 1
    },
    {
      "id": "022aa490-78eb-4ad3-ad61-7ce621541443",
      "name": "Sticky Note 7",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        2080,
        48
      ],
      "parameters": {
        "color": 5,
        "width": 320,
        "height": 372,
        "content": "## ‚ö° Performance Tips\n\n**Customization Options:**\n- **Buffer Time**: Adjust from 15s (line in check_delay)\n- **TTL Values**: Modify Redis key expiration times\n- **LLM Settings**: Tune temperature and frequency penalty\n- **System Message**: Customize AI behavior\n\n**Scaling Considerations:**\n- Each session runs independently\n- Redis handles thousands of concurrent sessions\n- No shared bottlenecks between users"
      },
      "typeVersion": 1
    }
  ],
  "active": false,
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "aa753eee-4ff4-448c-8696-cd277fe2301f",
  "connections": {
    "chat": {
      "main": [
        [
          {
            "node": "store",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "wait": {
      "main": [
        [
          {
            "node": "get_timestamp",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "count": {
      "main": [
        [
          {
            "node": "check_first_message",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "store": {
      "main": [
        [
          {
            "node": "count",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "extract": {
      "main": [
        [
          {
            "node": "get_message",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "timestamp": {
      "main": [
        [
          {
            "node": "wait",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "check_delay": {
      "main": [
        [
          {
            "node": "extract",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "wait",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "get_message": {
      "main": [
        [
          {
            "node": "set_message",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "set_message": {
      "main": [
        [
          {
            "node": "check_queue_is_empty",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "get_timestamp": {
      "main": [
        [
          {
            "node": "check_delay",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "redis_chat_memory": {
      "ai_memory": [
        [
          {
            "node": "AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "check_first_message": {
      "main": [
        [
          {
            "node": "timestamp",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "nothing",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "check_queue_is_empty": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "extract",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  }
}