{
  "meta": {
    "site": "https://github.com/zengfr/n8n-workflow-all-templates",
    "name": "Smart Chat Routing Between Gemini and GPT Models Based on Query Complexity",
    "wechat": "youandme10086",
    "id": 9247,
    "update_time": "2025-11-10"
  },
  "nodes": [
    {
      "id": "77530f0b-8f16-4427-a45c-54c82c66588a",
      "name": "Model Selector",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        1184,
        1904
      ],
      "parameters": {
        "text": "={{ $json.chatInput }}",
        "options": {
          "systemMessage": "=# Overview\nYou are an AI agent responsible for selecting the most suitable large language model to handle a given user request. Determine whether the question is simple or complex.\n\n## Instructions\nAnalyze the user's request and return only a single number based on the complexity of the task.\n\n## Classification Rules\n- **Output 1**: Complex questions requiring deep reasoning, professional writing, research, coding, or multi-step problem solving\n- **Output 2**: Simple questions that are straightforward, conversational, or can be answered quickly\n\n## Output Format\nReturn only one of the following:\n- 1\n- 2\n\nNo explanations, no newline or spaces, no formatting, no extra text. Only the number."
        },
        "promptType": "define"
      },
      "typeVersion": 1.9
    },
    {
      "id": "9fe14e1d-1f15-4095-b338-c96ef00a9b47",
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "position": [
        976,
        1904
      ],
      "webhookId": "2c54aa53-9406-4d0c-9217-d78b8f9cb137",
      "parameters": {
        "options": {}
      },
      "typeVersion": 1.3
    },
    {
      "id": "530ca74e-ff27-4400-8527-57e9d62e3a61",
      "name": "Model selector",
      "type": "@n8n/n8n-nodes-langchain.modelSelector",
      "position": [
        1440,
        2096
      ],
      "parameters": {
        "rules": {
          "rule": [
            {
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "f7148b18-d2be-4618-a12c-6f144f1eab14",
                    "operator": {
                      "type": "number",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $('Model Selector').item.json.output.toNumber() }}",
                    "rightValue": 1
                  }
                ]
              }
            },
            {
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "c30c1080-35d3-4cf0-a871-8034049d9d10",
                    "operator": {
                      "type": "number",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $('Model Selector').item.json.output.toNumber() }}",
                    "rightValue": 2
                  }
                ]
              }
            }
          ]
        }
      },
      "typeVersion": 1
    },
    {
      "id": "ba211db9-bf65-4f71-9755-a47ebfea1b86",
      "name": "Main Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        1520,
        1904
      ],
      "parameters": {
        "text": "={{ $('When chat message received').item.json.chatInput }}",
        "options": {
          "systemMessage": "=Here is the current date/time: {{ $now }}"
        },
        "promptType": "define"
      },
      "typeVersion": 2.2
    },
    {
      "id": "6afd02b9-9a79-40fc-a26c-e73b837d3eda",
      "name": "4.1 nano",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        1488,
        2352
      ],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "id",
          "value": "=gpt-4.1-nano"
        },
        "options": {}
      },
      "credentials": {
        "openAiApi": {
          "id": "ymMvgDroJHalwvRf",
          "name": "OpenAI"
        }
      },
      "typeVersion": 1.2
    },
    {
      "id": "83ca2ffd-aff1-482b-b87b-052e9f9cc193",
      "name": "2.5 pro",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "position": [
        1440,
        2240
      ],
      "parameters": {
        "options": {},
        "modelName": "=models/gemini-2.5-pro"
      },
      "credentials": {
        "googlePalmApi": {
          "id": "7v8o9EaQkl33woxm",
          "name": "v9"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "9f603eb2-6ef2-43ef-8519-759eca7e91df",
      "name": "2.0 flash",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "position": [
        1184,
        2112
      ],
      "parameters": {
        "options": {},
        "modelName": "models/gemini-2.0-flash"
      },
      "credentials": {
        "googlePalmApi": {
          "id": "8XtobpsLkdYQTldy",
          "name": "Gemini v6"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "c60c1f49-3732-4307-9538-86fd8b93a58c",
      "name": "Overview Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        304,
        1776
      ],
      "parameters": {
        "color": 4,
        "width": 600,
        "height": 1000,
        "content": "# Adaptive LLM Router for Optimized AI Chat Responses\n\n## üìã What This Template Does\nThis workflow creates an intelligent chat agent that classifies incoming queries by complexity and routes them to the appropriate LLM: Gemini 2.5 Pro for complex tasks, OpenAI GPT-4.1 Nano for simple ones‚Äîoptimizing for cost and performance.\n\n## üîß Prerequisites\n- n8n instance with LangChain nodes enabled\n- Access to Google Gemini and OpenAI APIs\n\n## üîë Required Credentials\n\n### OpenAI API Setup\n1. Go to platform.openai.com/api-keys\n2. Create new secret key\n3. Add to n8n as OpenAI API credential\n\n### Google Gemini API Setup\n1. Visit makersuite.google.com/app/apikey\n2. Generate API key\n3. Add to n8n as Google PaLM API credential\n\n## ‚öôÔ∏è Configuration Steps\n1. Import workflow JSON into n8n\n2. Assign credentials to LLM nodes\n3. Activate the workflow\n4. Test via chat input (use n8n's chat interface or integrate with external tools)\n\n## üéØ Use Cases\n- Cost-effective AI assistants for customer support\n- Dynamic query handling in educational bots\n- Optimized response generation for content tools\n- Efficient processing in research assistants\n\n## ‚ö†Ô∏è Troubleshooting\n- Classification errors: Refine prompt in Model Selector\n- API issues: Check credentials and quotas\n- No response: Ensure webhook is active; test nodes individually\n- Output parsing: Verify selector outputs only 1 or 2"
      },
      "typeVersion": 1
    },
    {
      "id": "00acaca1-2394-4609-bfc0-409c1f281194",
      "name": "Note: Trigger",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        928,
        2096
      ],
      "parameters": {
        "width": 252,
        "height": 192,
        "content": "## üì• When chat message received\n\n**Purpose:** For real-time chat."
      },
      "typeVersion": 1
    },
    {
      "id": "fb5bad8f-6436-4a67-b0d5-fe7c2a3a58df",
      "name": "Note: Classifier",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1152,
        1712
      ],
      "parameters": {
        "color": 2,
        "width": 332,
        "content": "## ü§ñModel Selector\n\n**Purpose:** Classifies query complexity.\n\n**Note:** Outputs 1 (complex) or 2 (simple)."
      },
      "typeVersion": 1
    },
    {
      "id": "f91cfe72-69c0-4627-b508-0159497317ca",
      "name": "Note: Main Agent",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1744,
        2048
      ],
      "parameters": {
        "color": 5,
        "width": 284,
        "height": 192,
        "content": "## üí¨ Node: Main Agent\n\n**Purpose:** Generates response with selected model.\n\n**Note:** Includes current date in prompt."
      },
      "typeVersion": 1
    }
  ],
  "pinData": {},
  "connections": {
    "2.5 pro": {
      "ai_languageModel": [
        [
          {
            "node": "Model selector",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "4.1 nano": {
      "ai_languageModel": [
        [
          {
            "node": "Model selector",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "2.0 flash": {
      "ai_languageModel": [
        [
          {
            "node": "Model Selector",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Model Selector": {
      "main": [
        [
          {
            "node": "Main Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Model selector": {
      "ai_languageModel": [
        [
          {
            "node": "Main Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "Model Selector",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  }
}