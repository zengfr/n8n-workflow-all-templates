{
  "meta": {
    "site": "https://github.com/zengfr/n8n-workflow-all-templates",
    "name": "Automated Cover Letter Generator with Indeed Job Scraping and GPT-4o-mini",
    "wechat": "youandme10086",
    "id": 7602,
    "update_time": "2025-11-10"
  },
  "nodes": [
    {
      "id": "4611b1b2-cfd3-4fa6-8bd0-fb60af4ea140",
      "name": "Sticky Note25",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -2016,
        6336
      ],
      "parameters": {
        "width": 400,
        "height": 928,
        "content": "## ‚öôÔ∏è Setup Instructions\n\n### 1Ô∏è‚É£ Set Up OpenAI Connection\n1. Go to [OpenAI Platform](https://platform.openai.com/api-keys)  \n2. Navigate to [OpenAI Billing](https://platform.openai.com/settings/organization/billing/overview)  \n3. Add funds to your billing account  \n4. Copy your API key into the **OpenAI credentials** in n8n  \n\n### 2Ô∏è‚É£ Set Up Apify Connection\n1. Go to [Apify Console](https://console.apify.com/) and sign up/login  \n2. Get your API token here: [Apify API Keys](https://console.apify.com/account/integrations)  \n3. Set up this scrapers in your Apify account:  \n   - [Indeed Scraper](https://apify.com/misceres/indeed-scraper)  \n \n4. In n8n, create a **HTTP Query Auth** credential  \n   - Query Key: `token`  \n   - Value: `YOUR_APIFY_API_KEY`  \n5. Attach this credential to both **HTTP Request nodes** (`Search Indeed`)  \n\n---\n\n\n## üì¨ Contact Information\nNeed help customizing this workflow or building similar automations?  \n\nüìß [robert@ynteractive.com](mailto:robert@ynteractive.com)  \nüîó [Robert Breen](https://www.linkedin.com/in/robert-breen-29429625/)  \nüåê [ynteractive.com](https://ynteractive.com)  \n"
      },
      "typeVersion": 1
    },
    {
      "id": "2d028c83-928b-4aa7-9db6-df943a54efa7",
      "name": "Sticky Note26",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -1568,
        6336
      ],
      "parameters": {
        "color": 7,
        "width": 1104,
        "height": 928,
        "content": "# üìù Job Application Cover Letter Generator (n8n + Apify + OpenAI)\n\nThis workflow automates the process of writing tailored **cover letters** for job applications. It:  \n1. Uses **Apify‚Äôs Indeed Scraper** to pull live job postings based on your chosen search term.  \n2. Sends the job description along with your resume into **OpenAI**, which writes an optimized cover letter ‚Äî one paragraph plus bullet points ‚Äî only using details from your resume.  \n"
      },
      "typeVersion": 1
    },
    {
      "id": "a1fdbd4e-a0bb-4911-8cef-c3856f8626ae",
      "name": "Structured Output Parser6",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "position": [
        -656,
        6992
      ],
      "parameters": {
        "jsonSchemaExample": "{\n\t\"cover letter\": \"Cover Letter\"\n}"
      },
      "typeVersion": 1.3
    },
    {
      "id": "3336aa65-7a52-4bdc-bbfd-cf760ac45491",
      "name": "OpenAI Chat Model8",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        -944,
        6992
      ],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4o-mini",
          "cachedResultName": "gpt-4o-mini"
        },
        "options": {}
      },
      "credentials": {
        "openAiApi": {
          "id": "4l6TDfLZVFS24g3X",
          "name": "OpenAi account 4"
        }
      },
      "typeVersion": 1.2
    },
    {
      "id": "21a8bbc6-823a-4b3e-a854-888bc19c7198",
      "name": "Sticky Note27",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -1056,
        6816
      ],
      "parameters": {
        "color": 3,
        "width": 288,
        "height": 304,
        "content": "### 1Ô∏è‚É£ Set Up OpenAI Connection\n1. Go to [OpenAI Platform](https://platform.openai.com/api-keys)  \n2. Navigate to [OpenAI Billing](https://platform.openai.com/settings/organization/billing/overview)  \n3. Add funds to your billing account  \n4. Copy your API key into the **OpenAI credentials** in n8n  "
      },
      "typeVersion": 1
    },
    {
      "id": "9db8438f-5e7b-4013-b558-1a3523383f9c",
      "name": "Sticky Note28",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -1488,
        6720
      ],
      "parameters": {
        "color": 3,
        "width": 288,
        "height": 496,
        "content": "### 2Ô∏è‚É£ Set Up Apify Connection\n1. Go to [Apify Console](https://console.apify.com/) and sign up/login  \n2. Get your API token here: [Apify API Keys](https://console.apify.com/account/integrations)  \n3. Set up this scrapers in your Apify account:  \n   - [Indeed Scraper](https://apify.com/misceres/indeed-scraper)  \n \n4. In n8n, create a **HTTP Query Auth** credential  \n   - Query Key: `token`  \n   - Value: `YOUR_APIFY_API_KEY`  \n5. Attach this credential to both **HTTP Request nodes** (`Search Indeed`)  \n"
      },
      "typeVersion": 1
    },
    {
      "id": "3f69158f-bce2-4a9c-aafa-3b24ef3c20d6",
      "name": "When clicking ‚ÄòExecute workflow‚Äô",
      "type": "n8n-nodes-base.manualTrigger",
      "position": [
        -1504,
        6528
      ],
      "parameters": {},
      "typeVersion": 1
    },
    {
      "id": "0abc8a89-9e13-4757-924e-bcf848f63595",
      "name": "Search Indeed",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        -1392,
        7072
      ],
      "parameters": {
        "url": "=https://api.apify.com/v2/acts/misceres~indeed-scraper/run-sync-get-dataset-items\n",
        "method": "POST",
        "options": {},
        "jsonBody": "={\n    \"country\": \"US\",\n    \"followApplyRedirects\": false,\n    \"location\": \"remote\",\n    \"maxItems\": 10,\n    \"parseCompanyDetails\": true,\n    \"position\": \"{{ $json.Search }}\",\n    \"saveOnlyUniqueItems\": true\n}",
        "sendBody": true,
        "specifyBody": "json",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpQueryAuth"
      },
      "credentials": {
        "httpQueryAuth": {
          "id": "wR5zdRq0CfAhl2yx",
          "name": "Query Auth account"
        }
      },
      "typeVersion": 4.2
    },
    {
      "id": "cc81c60d-ce2f-40d0-8e4f-bfa83d6a2686",
      "name": "Cover Letter Writer",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        -928,
        6576
      ],
      "parameters": {
        "text": "=Job Description: {{ $json.description }} Resume: {{ $('Set Search Term').item.json.Resume }}",
        "options": {
          "systemMessage": "Write an optimized cover letter for the incoming job description. Look to the resume for ideas on what to include. Do not make anything up, only use content from the resume. The cover letter should be one paragraph with bullet points after. \n\n\nOutput data like this. \n{\n\t\"cover letter\": \"Cover Letter\"\n}"
        },
        "promptType": "define",
        "hasOutputParser": true
      },
      "typeVersion": 2.2
    },
    {
      "id": "0e005bc4-2064-47ca-b586-68e80895b677",
      "name": "Set Search Term",
      "type": "n8n-nodes-base.set",
      "position": [
        -1328,
        6528
      ],
      "parameters": {
        "options": {},
        "assignments": {
          "assignments": [
            {
              "id": "86221d8e-18d1-4a37-9ffe-b31db3a3441d",
              "name": "Search",
              "type": "string",
              "value": "n8n"
            },
            {
              "id": "9dc419c9-2243-4bcb-bf56-1ba27e0544b1",
              "name": "Resume",
              "type": "string",
              "value": "ROBERT BREEN     (814) 882-1293              https://www.linkedin.com/in/robert-breen-29429625/   Robert.j.Breen@gmail.com   n8n Top Supporter: https://community.n8n.io/u/rbreen/badges;  n8n Top Creator:   https://n8n.io/creators/rbreen/       PROFESSIONAL SKILLSET\t  ÔÉº\tn8n Top Supporter\tÔÉº\tAI Agents ÔÉº\tn8n, OpenAI, Google Gemini\tÔÉº\tLow Code Automation ÔÉº\tPython & SQL\tÔÉº\tAI & Automation ÔÉº\tGenerative AI \tÔÉº\tAugmented Generation (RAG) Systems ÔÉº\tProcess Automation\tÔÉº\tMake.com & Zapier CAREER HIGHLIGHTS  ‚Ä¢\tDesigned and deployed AI agents using n8n + GPT-4/Gemini that autonomously book meetings, qualify leads, summarize documents, and route tasks ‚Äî replacing hours of daily manual work. ‚Ä¢\tBuilt retrieval-augmented generation (RAG) pipelines with Supabase and Google Drive, enabling agents to access, read, and respond to questions using custom document databases. ‚Ä¢\tCreated multi-step, low-code automation systems that connect Gmail, Google Calendar, Notion, Slack, Airtable, and more ‚Äî allowing AI agents to take contextual action across platforms. ‚Ä¢\tEngineered reusable AI agent templates for scheduling, internal task automation, and lead intake, enabling businesses to rapidly deploy scalable AI-driven workflows. ‚Ä¢\tDelivered hands-on AI automation training, including 1-on-1 coaching and live workshops teaching professionals how to build agents with n8n, ChatGPT, and Google Gemini. ‚Ä¢\tAuthored and published an AI automation tutorial series on YouTube, reaching thousands of viewers and providing step-by-step guides to building smart agents and business automations. ‚Ä¢\tDeveloped custom prompt engineering frameworks for agents with memory, goal-setting, and context awareness, improving accuracy and user satisfaction across automated systems. ‚Ä¢\tIntegrated real-time AI assistants into business operations, reducing human task load by up to 80% and accelerating decision cycles through intelligent agent recommendations. ‚Ä¢\tAutomated internal reporting, client onboarding, and data movement tasks using a blend of Python, API integrations, and generative AI, creating end-to-end systems that operate with minimal oversight.   EXPERIENCE  Ynteractive‚Äì Palmyra, Pa        \t\t\t\t                                                                         01/2022 - Present  AI Consultant ‚Äì n8n Specialist \t\t\t\t\t\t\t As an AI Consultant, I specialize in building end-to-end AI-powered automation systems that streamline operations, reduce manual workloads, and scale intelligently. My focus is on developing custom AI agents using tools like n8n, ChatGPT, and Google Gemini, enabling businesses to automate decision-making, communication, scheduling, lead intake, and internal workflows. These agents go beyond simple automation ‚Äî they use memory, reasoning, and APIs to take contextual action across tools like Gmail, Notion, Slack, and Google Calendar.  I leverage my background in data engineering to build robust pipelines and backend systems using Python, SQL, and platforms like Supabase, Databricks, and PostgreSQL. These systems power intelligent agents with clean, structured data and seamless API access. I work closely with founders, marketing teams, and operations leaders to identify automation opportunities, define AI agent behaviors, and implement solutions that run 24/7. My goal is to empower organizations with scalable, generative AI systems that save time, reduce overhead, and unlock new levels of operational efficiency.        \t Databricks. ‚Äì Palmyra, Pa        \t\t\t\t                                                                      07/2022 ‚Äì 03/2024  Marketing Analytics        \t\t\t\t\t\t\t Experienced Tableau Developer and Marketing Analyst with a proven track record at Databricks, a leading technology company. Skilled in leveraging data-driven insights to support effective marketing strategies. Collaborate cross-functionally within the marketing department to develop dashboards and conduct data analysis, enabling the identification of emerging trends. Establish growth and expansion benchmarks for various marketing channels, including paid search/social, display, email marketing, events, and web. Build and oversee marketing reporting and dashboards, ensuring rigorous quality control and timely delivery of insights. Utilize quantitative analyses to generate recommendations for investment and marketing strategy enhancements, optimizing the effectiveness of marketing spend   .  Databrains ‚Äì Palmyra, Pa              \t\t                                                                                      05/2020 ‚Äì 01/2022   Analytics Consultant                          \t\t\t\t\t\t\t Develop solutions to client problems using a suite of Tableau products including Tableau Server, Desktop, and Prep Builder, along with data engineering tools such as Python, SQL, and ETL platforms. Collaborate with business users to analyze user requirements and ensure that data pipelines are optimized for effective reporting. By integrating data engineering practices, I create efficient data workflows that ensure accurate, timely, and insightful data for decision-making.  I also identify and solve problems using data analysis, engineering experience, and decision-making skills to build scalable solutions. I provide thought leadership, best practices, and standards required to deliver effective Tableau solutions to clients, while overseeing the end-to-end data architecture and analytics platforms. This ensures that data pipelines and transformations provide high-quality insights into customer behavior and business performance.    Frontline Performance Group ‚Äì Winter Park, FL                                                                              01/2018 ‚Äì 05/2020   Business Intelligence Analyst\t\t\t\t Gather and document business requirements to develop enterprise-wide business intelligence solutions. Build and maintain BI reporting dashboards to support field operations and executive leadership. Integrate data from various desperate systems to provide thorough reporting Interface with business users, and software implementation team to support proprietary software implementation. Automate reporting processes with Tableau Software. Convert integral reports from Microsoft excel to Tableau Software solutions.  The Institute of Internal Auditors ‚Äì Lake Mary, FL                                                                         05/2015 ‚Äì 01/2018   Business Analyst                     \t\t\t\t\t\t\t Identify and monitor current and potential customers, using business intelligence tools. Develop in-depth understanding of underlying data, data structures, KPIs, and business uses of data to provide clear data visualizations and analysis. Analyze and document existing processes to expose business process efficiencies. Work with individual teams to create real-time KPI dashboards. Maintain profitable strategies, processes and procedures around foundation operations. Develop budgets and forecasts to plan effectively for each fiscal year, and business cycle Continually answer business questions through analysis of data. Implement new reporting dashboards.      EDUCATIONAL BACKGROUND Bachelor‚Äôs Degree, Bachelor of Science Slippery Rock University, Slippery Rock, PA‚Äì 05/2009"
            }
          ]
        }
      },
      "typeVersion": 3.4
    }
  ],
  "pinData": {},
  "connections": {
    "Search Indeed": {
      "main": [
        [
          {
            "node": "Cover Letter Writer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set Search Term": {
      "main": [
        [
          {
            "node": "Search Indeed",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model8": {
      "ai_languageModel": [
        [
          {
            "node": "Cover Letter Writer",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Cover Letter Writer": {
      "main": [
        []
      ]
    },
    "Structured Output Parser6": {
      "ai_outputParser": [
        [
          {
            "node": "Cover Letter Writer",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "When clicking ‚ÄòExecute workflow‚Äô": {
      "main": [
        [
          {
            "node": "Set Search Term",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  }
}