{
  "meta": {
    "site": "https://github.com/zengfr/n8n-workflow-all-templates",
    "name": "Build an On-Premises AI Kaggle Competition Assistant with Qdrant RAG and Ollama",
    "wechat": "youandme10086",
    "id": 3967,
    "update_time": "2025-11-10"
  },
  "nodes": [
    {
      "id": "70b42807-a6c6-4159-b278-e77311727798",
      "name": "Local File Trigger",
      "type": "n8n-nodes-base.localFileTrigger",
      "position": [
        -3060,
        -40
      ],
      "parameters": {
        "path": "C:\\\\ipynb\\\\loadme",
        "events": [
          "add"
        ],
        "options": {
          "usePolling": true,
          "followSymlinks": true,
          "awaitWriteFinish": true
        },
        "triggerOn": "folder"
      },
      "typeVersion": 1
    },
    {
      "id": "893f1157-6c00-4b8e-b726-462ab371fadf",
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "position": [
        -1500,
        300
      ],
      "parameters": {
        "options": {}
      },
      "typeVersion": 1
    },
    {
      "id": "9a9bfcee-1966-415c-a59f-552e1f35aae9",
      "name": "Recursive Character Text Splitter",
      "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "position": [
        -1360,
        440
      ],
      "parameters": {
        "options": {},
        "chunkSize": 40,
        "chunkOverlap": 10
      },
      "typeVersion": 1
    },
    {
      "id": "a7c971a5-39ac-4715-9e1b-a56af9713b06",
      "name": "Settings",
      "type": "n8n-nodes-base.set",
      "position": [
        -3040,
        180
      ],
      "parameters": {
        "options": {},
        "assignments": {
          "assignments": [
            {
              "id": "6b7d26f9-3a38-417e-85d0-4e9d42476465",
              "name": "path",
              "type": "string",
              "value": "=C:\\\\ipynb\\\\loadme\\\\"
            },
            {
              "id": "bb4471c7-d894-4739-99a6-4be247794ffa",
              "name": "filename",
              "type": "string",
              "value": "={{ $json.path.split('\\\\').last() }}"
            }
          ]
        }
      },
      "typeVersion": 3.3
    },
    {
      "id": "6384792b-de76-4e43-b26e-12c2d15c2dd2",
      "name": "Merge",
      "type": "n8n-nodes-base.merge",
      "position": [
        -1740,
        260
      ],
      "parameters": {},
      "typeVersion": 2.1
    },
    {
      "id": "db4de019-755e-4b91-ac70-f30825f14033",
      "name": "Get FileType",
      "type": "n8n-nodes-base.switch",
      "position": [
        -2620,
        80
      ],
      "parameters": {
        "rules": {
          "values": [
            {
              "outputKey": "html",
              "conditions": {
                "options": {
                  "version": 1,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "75188d2f-4bea-44ea-a579-9b9a1bd1ea93",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $json.fileType }}",
                    "rightValue": "html"
                  }
                ]
              },
              "renameOutput": true
            }
          ]
        },
        "options": {}
      },
      "typeVersion": 3
    },
    {
      "id": "4c56a14c-6c56-4cc1-b7fb-a09caa3d646d",
      "name": "Import File",
      "type": "n8n-nodes-base.readWriteFile",
      "position": [
        -2840,
        80
      ],
      "parameters": {
        "options": {},
        "fileSelector": "={{ $json.path }}{{ $json.filename }}"
      },
      "typeVersion": 1
    },
    {
      "id": "c14a711f-29ab-475f-aeff-3a070c797537",
      "name": "Extract from TEXT",
      "type": "n8n-nodes-base.extractFromFile",
      "position": [
        -2440,
        80
      ],
      "parameters": {
        "options": {},
        "operation": "text"
      },
      "typeVersion": 1
    },
    {
      "id": "22ff782e-c612-4928-9033-111cf516d07e",
      "name": "Summarization Chain",
      "type": "@n8n/n8n-nodes-langchain.chainSummarization",
      "position": [
        -2040,
        -20
      ],
      "parameters": {
        "options": {
          "summarizationMethodAndPrompts": {
            "values": {
              "summarizationMethod": "refine"
            }
          }
        },
        "chunkSize": 4000
      },
      "typeVersion": 2
    },
    {
      "id": "70fa17a5-3ec9-4a81-86bc-503581505ea1",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -3100,
        -180
      ],
      "parameters": {
        "color": 7,
        "width": 995,
        "height": 554,
        "content": "## Step 1. Watch Folder and Import New Documents\n[Read more about Local File Trigger](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.localfiletrigger)\n\nWith n8n's local file trigger, we're able to trigger the workflow when files are created in our target folder. We still have to import them however as the trigger will only give the file's path. The \"Extract From\" node is used to get at the file's contents."
      },
      "typeVersion": 1
    },
    {
      "id": "a51cc8ac-e310-4825-adc6-fc57c68c09aa",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -2060,
        -200
      ],
      "parameters": {
        "color": 7,
        "width": 824,
        "height": 770,
        "content": "## Step 2. Summarise and Vectorise Document Contents\n[Learn more about using the Qdrant VectorStore](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreqdrant)\n\nCapturing the document into our vector store is intended for a technique we'll use later known as Retrieval Augumented Generation or \"RAG\" for short. For our scenario, this allows our LLM to retrieve context more efficiently which produces better respsonses."
      },
      "typeVersion": 1
    },
    {
      "id": "6d59dc6a-692a-4752-a811-8b3033898fa4",
      "name": "Qdrant Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "position": [
        -1600,
        60
      ],
      "parameters": {
        "mode": "insert",
        "options": {},
        "qdrantCollection": {
          "__rl": true,
          "mode": "id",
          "value": "test_rag"
        }
      },
      "credentials": {
        "qdrantApi": {
          "id": "wqHGuxoW5RJJYSIl",
          "name": "QdrantApi account"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "f75f45cd-4aed-48a2-bb09-5db20b00a029",
      "name": "Markdown",
      "type": "n8n-nodes-base.markdown",
      "position": [
        -2260,
        80
      ],
      "parameters": {
        "html": "={{ $json.data }}",
        "options": {}
      },
      "typeVersion": 1
    },
    {
      "id": "34fdd670-f568-4351-81c7-79fde68b8192",
      "name": "Embeddings Ollama",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOllama",
      "position": [
        -1560,
        420
      ],
      "parameters": {
        "model": "mxbai-embed-large:latest"
      },
      "credentials": {
        "ollamaApi": {
          "id": "jBqODDnXWJw9rGcS",
          "name": "Ollama account"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "4c4f71db-e496-4528-b0e5-dc5ffb27a2e8",
      "name": "Ollama Summarizer",
      "type": "@n8n/n8n-nodes-langchain.lmOllama",
      "position": [
        -1900,
        140
      ],
      "parameters": {
        "model": "ALIENTELLIGENCE/contentsummarizer:latest",
        "options": {}
      },
      "credentials": {
        "ollamaApi": {
          "id": "jBqODDnXWJw9rGcS",
          "name": "Ollama account"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "0a2954cc-bec6-4750-ae75-6362761e41b6",
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "position": [
        -3020,
        540
      ],
      "webhookId": "9dd3e051-58a3-4c46-bd41-58c001f009f9",
      "parameters": {
        "options": {}
      },
      "typeVersion": 1.1
    },
    {
      "id": "1ebe053c-0e26-44c6-b543-756ad551b99d",
      "name": "AI Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        -2840,
        540
      ],
      "parameters": {
        "options": {
          "systemMessage": "This is a helpful and exacting data science LLM model and master Kaggle python programmer.\n\nIf Kaggle contest requirements are given from the chat input; first deeply research the problem.\n\nAccess the tool: \"previous_entry\" when preparing your background research.\n\nThen Ask any needed questions to clarify and understand the requirements necessary to build a program to address the challenge.\n\nReview your proposed program for errors and bugs.\n\nThen present the program.\n\nIf errors are returned; then iteratively debug with the chat user."
        }
      },
      "typeVersion": 1.7
    },
    {
      "id": "e042ec84-3bb6-466f-9957-0509a181d61b",
      "name": "Vector Store Tool",
      "type": "@n8n/n8n-nodes-langchain.toolVectorStore",
      "position": [
        -2580,
        740
      ],
      "parameters": {
        "name": "previous_entry",
        "description": "={{ $('When chat message received').item.json.chatInput }}"
      },
      "typeVersion": 1
    },
    {
      "id": "fbae9bc0-6ea4-4a26-ad76-eb84bc5d06c2",
      "name": "Window Buffer Memory",
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "position": [
        -2760,
        780
      ],
      "parameters": {
        "contextWindowLength": 15
      },
      "typeVersion": 1.3
    },
    {
      "id": "2f567628-fd1d-406b-aec7-46684bd6f5e6",
      "name": "Qdrant Vector Store2",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "position": [
        -2680,
        920
      ],
      "parameters": {
        "options": {},
        "qdrantCollection": {
          "__rl": true,
          "mode": "list",
          "value": "test_rag",
          "cachedResultName": "test_rag"
        }
      },
      "credentials": {
        "qdrantApi": {
          "id": "wqHGuxoW5RJJYSIl",
          "name": "QdrantApi account"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "3aea837f-7676-45da-b6b1-fb2f6c5f8cd9",
      "name": "Ollama Chat Model3",
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "position": [
        -2900,
        760
      ],
      "parameters": {
        "model": "qwen3:8b",
        "options": {}
      },
      "credentials": {
        "ollamaApi": {
          "id": "jBqODDnXWJw9rGcS",
          "name": "Ollama account"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "a9298132-e5b9-44a2-9928-a1adf7cf9fc4",
      "name": "Embeddings Ollama2",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOllama",
      "position": [
        -2660,
        1080
      ],
      "parameters": {
        "model": "mxbai-embed-large:latest"
      },
      "credentials": {
        "ollamaApi": {
          "id": "jBqODDnXWJw9rGcS",
          "name": "Ollama account"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "a1c71691-8e41-4633-a1ab-4991833fb7c6",
      "name": "Ollama Chat Model4",
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "position": [
        -2360,
        900
      ],
      "parameters": {
        "model": "qwen3:8b",
        "options": {}
      },
      "credentials": {
        "ollamaApi": {
          "id": "jBqODDnXWJw9rGcS",
          "name": "Ollama account"
        }
      },
      "typeVersion": 1
    }
  ],
  "pinData": {},
  "connections": {
    "Merge": {
      "main": [
        [
          {
            "node": "Qdrant Vector Store",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Markdown": {
      "main": [
        [
          {
            "node": "Summarization Chain",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Settings": {
      "main": [
        [
          {
            "node": "Import File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Import File": {
      "main": [
        [
          {
            "node": "Get FileType",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get FileType": {
      "main": [
        [
          {
            "node": "Extract from TEXT",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings Ollama": {
      "ai_embedding": [
        [
          {
            "node": "Qdrant Vector Store",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Extract from TEXT": {
      "main": [
        [
          {
            "node": "Markdown",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Summarizer": {
      "ai_languageModel": [
        [
          {
            "node": "Summarization Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Vector Store Tool": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings Ollama2": {
      "ai_embedding": [
        [
          {
            "node": "Qdrant Vector Store2",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Local File Trigger": {
      "main": [
        [
          {
            "node": "Settings",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Chat Model4": {
      "ai_languageModel": [
        [
          {
            "node": "Vector Store Tool",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Default Data Loader": {
      "ai_document": [
        [
          {
            "node": "Qdrant Vector Store",
            "type": "ai_document",
            "index": 0
          }
        ]
      ]
    },
    "Qdrant Vector Store": {
      "main": [
        []
      ]
    },
    "Summarization Chain": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Qdrant Vector Store2": {
      "ai_vectorStore": [
        [
          {
            "node": "Vector Store Tool",
            "type": "ai_vectorStore",
            "index": 0
          }
        ]
      ]
    },
    "Window Buffer Memory": {
      "ai_memory": [
        [
          {
            "node": "AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Recursive Character Text Splitter": {
      "ai_textSplitter": [
        [
          {
            "node": "Default Data Loader",
            "type": "ai_textSplitter",
            "index": 0
          }
        ]
      ]
    }
  }
}